{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lavanyashukla/genai-class/blob/main/SpaceRAG_initial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Pao9QWqE7yLn"
      },
      "outputs": [],
      "source": [
        "IN_COLAB = False\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    import os\n",
        "    os.environ[\"WANDB_API_KEY\"] = userdata.get(\"WANDB_API_KEY\")\n",
        "    os.environ[\"TOGETHER_API_KEY\"] = userdata.get(\"TOGETHER_API_KEY\")\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    from dotenv import load_dotenv\n",
        "    load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJNpOy777yLn",
        "outputId": "3935f4e2-e082-41b1-bc1e-aa63280899ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning repository: https://github.com/wandb/weave.git\n",
            "Successfully cloned examples/cookbooks from branch 'anish/add-spacerag-example' to weave_cookbooks\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import shutil\n",
        "\n",
        "repo_url = \"https://github.com/wandb/weave.git\"\n",
        "target_folder = \"weave_cookbooks\"\n",
        "subdirectory = \"examples/cookbooks\"\n",
        "branch = \"anish/add-spacerag-example\"\n",
        "\n",
        "if not os.path.exists(target_folder) and IN_COLAB:\n",
        "    print(f\"Cloning repository: {repo_url}\")\n",
        "\n",
        "    # Clone the entire repository to a temporary folder\n",
        "    temp_folder = \"temp_weave_repo\"\n",
        "    subprocess.run([\"git\", \"clone\", \"--depth\", \"1\", \"--branch\", branch, repo_url, temp_folder], check=True)\n",
        "\n",
        "    # Move the desired subdirectory to the target folder\n",
        "    shutil.move(os.path.join(temp_folder, subdirectory), target_folder)\n",
        "\n",
        "    # Remove the temporary folder\n",
        "    shutil.rmtree(temp_folder)\n",
        "\n",
        "    print(f\"Successfully cloned {subdirectory} from branch '{branch}' to {target_folder}\")\n",
        "\n",
        "else:\n",
        "    print(f\"Folder '{target_folder}' already exists.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPU5GWX27yLo",
        "outputId": "cf153ba1-2f3b-4d84-ee73-d958d68e80e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/weave_cookbooks/rag/spacerag/weave_cookbooks/rag/spacerag\n",
            "Requirement already satisfied: weave in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.51.18)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.9.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.52.2)\n",
            "Requirement already satisfied: together in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.3.3)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (1.0.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (3.1.0)\n",
            "Requirement already satisfied: ragas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.2.3)\n",
            "Requirement already satisfied: tonic-validate in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (6.1.0)\n",
            "Requirement already satisfied: emoji>=2.12.1 in /usr/local/lib/python3.10/dist-packages (from weave->-r requirements.txt (line 1)) (2.14.0)\n",
            "Requirement already satisfied: gql[aiohttp,requests] in /usr/local/lib/python3.10/dist-packages (from weave->-r requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.10/dist-packages (from weave->-r requirements.txt (line 1)) (24.1)\n",
            "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from weave->-r requirements.txt (line 1)) (2.9.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from weave->-r requirements.txt (line 1)) (13.9.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,>=8.3.0 in /usr/local/lib/python3.10/dist-packages (from weave->-r requirements.txt (line 1)) (9.0.0)\n",
            "Requirement already satisfied: uuid-utils>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from weave->-r requirements.txt (line 1)) (0.9.0)\n",
            "Requirement already satisfied: wandb>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from weave->-r requirements.txt (line 1)) (0.18.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai->-r requirements.txt (line 4)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai->-r requirements.txt (line 4)) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai->-r requirements.txt (line 4)) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai->-r requirements.txt (line 4)) (0.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai->-r requirements.txt (line 4)) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai->-r requirements.txt (line 4)) (4.12.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /usr/local/lib/python3.10/dist-packages (from together->-r requirements.txt (line 5)) (3.10.10)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from together->-r requirements.txt (line 5)) (8.1.7)\n",
            "Requirement already satisfied: eval-type-backport<0.3.0,>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from together->-r requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /usr/local/lib/python3.10/dist-packages (from together->-r requirements.txt (line 5)) (3.16.1)\n",
            "Requirement already satisfied: pillow<11.0.0,>=10.3.0 in /usr/local/lib/python3.10/dist-packages (from together->-r requirements.txt (line 5)) (10.4.0)\n",
            "Requirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.10/dist-packages (from together->-r requirements.txt (line 5)) (17.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from together->-r requirements.txt (line 5)) (2.32.3)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from together->-r requirements.txt (line 5)) (0.9.0)\n",
            "Requirement already satisfied: typer<0.13,>=0.9 in /usr/local/lib/python3.10/dist-packages (from together->-r requirements.txt (line 5)) (0.12.5)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 7)) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 7)) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 7)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 7)) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->-r requirements.txt (line 7)) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 7)) (0.24.7)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 7)) (6.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from ragas->-r requirements.txt (line 8)) (0.7.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (from ragas->-r requirements.txt (line 8)) (0.3.7)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.10/dist-packages (from ragas->-r requirements.txt (line 8)) (0.3.15)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (from ragas->-r requirements.txt (line 8)) (0.3.5)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (from ragas->-r requirements.txt (line 8)) (0.2.5)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ragas->-r requirements.txt (line 8)) (1.6.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from ragas->-r requirements.txt (line 8)) (1.4.4)\n",
            "Requirement already satisfied: pysbd>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from ragas->-r requirements.txt (line 8)) (0.3.4)\n",
            "Requirement already satisfied: aioboto3<13.0.0,>=12.4.0 in /usr/local/lib/python3.10/dist-packages (from tonic-validate->-r requirements.txt (line 9)) (12.4.0)\n",
            "Requirement already satisfied: google-generativeai<0.6.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from tonic-validate->-r requirements.txt (line 9)) (0.5.4)\n",
            "Requirement already satisfied: litellm<2.0.0,>=1.35.8 in /usr/local/lib/python3.10/dist-packages (from tonic-validate->-r requirements.txt (line 9)) (1.51.3)\n",
            "Requirement already satisfied: aiobotocore==2.12.3 in /usr/local/lib/python3.10/dist-packages (from aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->tonic-validate->-r requirements.txt (line 9)) (2.12.3)\n",
            "Requirement already satisfied: botocore<1.34.70,>=1.34.41 in /usr/local/lib/python3.10/dist-packages (from aiobotocore==2.12.3->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->tonic-validate->-r requirements.txt (line 9)) (1.34.69)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /usr/local/lib/python3.10/dist-packages (from aiobotocore==2.12.3->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->tonic-validate->-r requirements.txt (line 9)) (1.16.0)\n",
            "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from aiobotocore==2.12.3->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->tonic-validate->-r requirements.txt (line 9)) (0.12.0)\n",
            "Requirement already satisfied: boto3<1.34.70,>=1.34.41 in /usr/local/lib/python3.10/dist-packages (from aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->tonic-validate->-r requirements.txt (line 9)) (1.34.69)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together->-r requirements.txt (line 5)) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together->-r requirements.txt (line 5)) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together->-r requirements.txt (line 5)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together->-r requirements.txt (line 5)) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together->-r requirements.txt (line 5)) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together->-r requirements.txt (line 5)) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 4)) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 4)) (1.2.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.4 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->tonic-validate->-r requirements.txt (line 9)) (0.6.4)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->tonic-validate->-r requirements.txt (line 9)) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->tonic-validate->-r requirements.txt (line 9)) (2.137.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->tonic-validate->-r requirements.txt (line 9)) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->tonic-validate->-r requirements.txt (line 9)) (3.20.3)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->tonic-validate->-r requirements.txt (line 9)) (1.25.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 4)) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 4)) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 4)) (0.14.0)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.10/dist-packages (from litellm<2.0.0,>=1.35.8->tonic-validate->-r requirements.txt (line 9)) (8.5.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from litellm<2.0.0,>=1.35.8->tonic-validate->-r requirements.txt (line 9)) (3.1.4)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from litellm<2.0.0,>=1.35.8->tonic-validate->-r requirements.txt (line 9)) (4.23.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from litellm<2.0.0,>=1.35.8->tonic-validate->-r requirements.txt (line 9)) (0.19.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0.0->weave->-r requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0.0->weave->-r requirements.txt (line 1)) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together->-r requirements.txt (line 5)) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together->-r requirements.txt (line 5)) (2.2.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->weave->-r requirements.txt (line 1)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->weave->-r requirements.txt (line 1)) (2.18.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->ragas->-r requirements.txt (line 8)) (2024.9.11)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<0.13,>=0.9->together->-r requirements.txt (line 5)) (1.5.4)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.1->weave->-r requirements.txt (line 1)) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.1->weave->-r requirements.txt (line 1)) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.1->weave->-r requirements.txt (line 1)) (4.3.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.1->weave->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.1->weave->-r requirements.txt (line 1)) (2.17.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.1->weave->-r requirements.txt (line 1)) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.1->weave->-r requirements.txt (line 1)) (75.1.0)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.2 in /usr/local/lib/python3.10/dist-packages (from gql[aiohttp,requests]->weave->-r requirements.txt (line 1)) (3.2.5)\n",
            "Requirement already satisfied: backoff<3.0,>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from gql[aiohttp,requests]->weave->-r requirements.txt (line 1)) (2.2.1)\n",
            "Requirement already satisfied: requests-toolbelt<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gql[aiohttp,requests]->weave->-r requirements.txt (line 1)) (1.0.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain->ragas->-r requirements.txt (line 8)) (2.0.35)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain->ragas->-r requirements.txt (line 8)) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain->ragas->-r requirements.txt (line 8)) (0.1.137)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core->ragas->-r requirements.txt (line 8)) (1.33)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community->ragas->-r requirements.txt (line 8)) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community->ragas->-r requirements.txt (line 8)) (0.4.0)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community->ragas->-r requirements.txt (line 8)) (2.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 7)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 7)) (2024.2)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas->-r requirements.txt (line 8)) (3.23.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas->-r requirements.txt (line 8)) (0.9.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.17.1->weave->-r requirements.txt (line 1)) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.17.1->weave->-r requirements.txt (line 1)) (4.0.11)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->tonic-validate->-r requirements.txt (line 9)) (1.65.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->tonic-validate->-r requirements.txt (line 9)) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->tonic-validate->-r requirements.txt (line 9)) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->tonic-validate->-r requirements.txt (line 9)) (4.9)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.8.0->litellm<2.0.0,>=1.35.8->tonic-validate->-r requirements.txt (line 9)) (3.20.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm<2.0.0,>=1.35.8->tonic-validate->-r requirements.txt (line 9)) (3.0.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas->-r requirements.txt (line 8)) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.35.8->tonic-validate->-r requirements.txt (line 9)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.35.8->tonic-validate->-r requirements.txt (line 9)) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.35.8->tonic-validate->-r requirements.txt (line 9)) (0.20.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain->ragas->-r requirements.txt (line 8)) (3.10.10)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->weave->-r requirements.txt (line 1)) (0.1.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain->ragas->-r requirements.txt (line 8)) (3.1.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.9.3->together->-r requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->tonic-validate->-r requirements.txt (line 9)) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->tonic-validate->-r requirements.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->tonic-validate->-r requirements.txt (line 9)) (4.1.1)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3<1.34.70,>=1.34.41->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->tonic-validate->-r requirements.txt (line 9)) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3<1.34.70,>=1.34.41->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->tonic-validate->-r requirements.txt (line 9)) (0.10.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.17.1->weave->-r requirements.txt (line 1)) (5.0.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->tonic-validate->-r requirements.txt (line 9)) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->tonic-validate->-r requirements.txt (line 9)) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.2->tonic-validate->-r requirements.txt (line 9)) (3.2.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->tonic-validate->-r requirements.txt (line 9)) (0.6.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas->-r requirements.txt (line 8)) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(target_folder) and IN_COLAB:\n",
        "    %cd weave_cookbooks/rag/spacerag\n",
        "    !pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "W38uw2oh7yLr"
      },
      "outputs": [],
      "source": [
        "import weave\n",
        "from weave import Evaluation\n",
        "import os\n",
        "import numpy as np\n",
        "import faiss\n",
        "from openai import OpenAI\n",
        "from together import Together\n",
        "import re\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjF12eEJ7yLr",
        "outputId": "eb3a726a-7a59-4a86-c253-54187c778c53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gql.transport.requests:>>> {\"query\": \"query DefaultEntity {\\n  viewer {\\n    username\\n    defaultEntity {\\n      name\\n    }\\n  }\\n}\"}\n",
            "INFO:gql.transport.requests:<<< {\"data\":{\"viewer\":{\"username\":\"lavanyashukla\",\"defaultEntity\":{\"name\":\"lavanyashukla\"}}}}\n",
            "INFO:gql.transport.requests:>>> {\"query\": \"query DefaultEntity {\\n  viewer {\\n    username\\n    defaultEntity {\\n      name\\n    }\\n  }\\n}\"}\n",
            "INFO:gql.transport.requests:<<< {\"data\":{\"viewer\":{\"username\":\"lavanyashukla\",\"defaultEntity\":{\"name\":\"lavanyashukla\"}}}}\n",
            "INFO:weave.trace_server_bindings.remote_http_trace_server:retry_attempt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logged in as Weights & Biases user: lavanyashukla.\n",
            "View Weave data at https://wandb.ai/lavanyashukla/spacerag_novtest2/weave\n"
          ]
        }
      ],
      "source": [
        "weave.init('spacerag_novtest2')\n",
        "\n",
        "# SERVE MODEL FROM TOGETHER ENDPOINT\n",
        "client = Together(api_key=os.environ.get(\"TOGETHER_API_KEY\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "hGbs2ryx7yLs"
      },
      "outputs": [],
      "source": [
        "# CHUNK DATA FROM EXTERNAL KNOWLEDGEBASE\n",
        "@weave.op\n",
        "def get_chunked_data(file):\n",
        "    # get data - file\n",
        "    with open(file, 'r') as file:\n",
        "        # Read the contents of the file into a variable\n",
        "        text = file.read()\n",
        "\n",
        "    # split doc into chunks\n",
        "    chunk_size = 10000 # 🛠️LEVER\n",
        "    chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)] # 🛠️LEVER (advanced)\n",
        "    return chunks\n",
        "\n",
        "# EMBED DATA\n",
        "@weave.op\n",
        "def get_text_embedding(input):\n",
        "    api_key_openai = os.environ[\"OPENAI_API_KEY\"]\n",
        "    client = OpenAI(api_key=api_key_openai)\n",
        "\n",
        "    response = client.embeddings.create(\n",
        "        model=\"text-embedding-3-small\", # 🛠️LEVER\n",
        "        input=input\n",
        "    )\n",
        "    return response.data[0].embedding\n",
        "\n",
        "# MAKE VECTORDB\n",
        "@weave.op\n",
        "def make_vector_db(file):\n",
        "    # get chunked data from function get_chunked_data()\n",
        "    chunks = get_chunked_data(file)\n",
        "    # embed data\n",
        "    text_embeddings = np.array([get_text_embedding(chunk) for chunk in chunks])\n",
        "    # embed data into vectordb\n",
        "    d = text_embeddings.shape[1]\n",
        "    index = faiss.IndexFlatL2(d)\n",
        "    index.add(text_embeddings)\n",
        "    return index, chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRh3mP_L7yLs",
        "outputId": "f213b983-d637-4646-d1a6-2dce9c954078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:weave.trace_server_bindings.remote_http_trace_server:retry_attempt\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8d8-d5ee-7672-9706-9a5b1dba66c1\n"
          ]
        }
      ],
      "source": [
        "file = './data/space.txt'\n",
        "index, chunks = make_vector_db(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "f8RuuvYW7yLt"
      },
      "outputs": [],
      "source": [
        "# ANSWER QUESTION\n",
        "@weave.op\n",
        "def predict(model, prompt):\n",
        "    completion = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\":\"user\",\"content\":prompt}],\n",
        "        temperature=1.0, # 🛠️LEVER\n",
        "        top_k=1000, # 🛠️LEVER\n",
        "        max_tokens=1024,\n",
        "        stream=True\n",
        "    )\n",
        "\n",
        "    answer = []\n",
        "    for chunk in completion:\n",
        "        if chunk.choices[0].delta.content is not None:\n",
        "            answer.append(chunk.choices[0].delta.content)\n",
        "\n",
        "    result = ''.join(answer)\n",
        "    print(result)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4mLorY2M7yLt"
      },
      "outputs": [],
      "source": [
        "# RETRIEVE CHUNKS SIMILAR TO THE QUESTION\n",
        "@weave.op\n",
        "def retrieve_context(question: str) -> list:\n",
        "    question_embeddings = np.array([get_text_embedding(question)])\n",
        "    # Retrieve similar chunks from the vectorDB\n",
        "    D, I = index.search(question_embeddings, k=1) # 🛠️LEVER k=?\n",
        "    retrieved_chunk = [chunks[i] for i in I.tolist()[0]]\n",
        "    return retrieved_chunk\n",
        "\n",
        "class SpaceRAGModel(weave.Model):\n",
        "    model: str\n",
        "\n",
        "    @weave.op()\n",
        "    def predict(self, question: str):\n",
        "        retrieved_chunk = retrieve_context(question)\n",
        "        print(\"Question: \"+question)\n",
        "\n",
        "        # Combine context and question in a prompt # 🛠️LEVER\n",
        "        prompt = f\"\"\"\n",
        "        Use this context to answer the question, don't use any prior knowledge.\n",
        "        Be concise in your answers.\n",
        "        ---------------------\n",
        "        {retrieved_chunk}\n",
        "        ---------------------\n",
        "        Question: {question}\n",
        "        Answer:\n",
        "        \"\"\"\n",
        "        answer = predict(self.model, prompt)\n",
        "        print(\"___________________________\")\n",
        "        return {'answer': answer, 'retrieved_chunk': retrieved_chunk}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "PpO97J2T7yLt"
      },
      "outputs": [],
      "source": [
        "def string_to_dict(input_string):\n",
        "    # Use regular expressions to find all JSON-like objects in the string\n",
        "    json_objects = re.findall(r'\\{.*?\\}', input_string)\n",
        "\n",
        "    # Initialize an empty dictionary to store the combined results\n",
        "    combined_dict = {}\n",
        "\n",
        "    for obj in json_objects:\n",
        "        try:\n",
        "            # Parse each JSON object\n",
        "            parsed_dict = json.loads(obj)\n",
        "            # Update the combined dictionary with the parsed data\n",
        "            combined_dict.update(parsed_dict)\n",
        "        except (ValueError, json.JSONDecodeError) as e:\n",
        "            print(f\"Error processing part: {obj}\\nError: {e}\")\n",
        "\n",
        "    return combined_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "KWA1mI3R7yLu"
      },
      "outputs": [],
      "source": [
        "dataset_ref = weave.ref(\"weave:///lavanyashukla/spacedata/object/space_dataset_llm_comprehensive:VBd5Ys7b3hGFmJJqdGTATVQYgKKrg70EiNV5FdpwFxs\").get()\n",
        "small_questions = dataset_ref.rows[:5] # 🔵 NOTE: CHANGE TO 5 WHEN RUNNING OUT YOUR EXPERIMENTS TO QUICKLY TEST.\n",
        "                                        # CHANGE BACK TO 50 BEFORE FINAL LEADERBOARD SUBMISSION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "8Ou5EOu07yLu"
      },
      "outputs": [],
      "source": [
        "def replace_nan_in_dict(result):\n",
        "    for key in result:\n",
        "        if isinstance(result[key], float) and np.isnan(result[key]):\n",
        "            result[key] = 0\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "h2K7y4jY7yLu"
      },
      "outputs": [],
      "source": [
        "# Evaluate with an LLM\n",
        "@weave.op\n",
        "def llm_judge_scorer(ground_truth: str, model_output: dict) -> dict:\n",
        "    scorer_llm = \"meta-llama/Meta-Llama-3-70B-Instruct-Turbo\"\n",
        "    answer = model_output['answer']\n",
        "    retrieved_chunk = model_output['retrieved_chunk']\n",
        "\n",
        "    eval_rubrics = [\n",
        "    {\n",
        "        \"metric\": \"concise\",\n",
        "        \"rubrics\": \"\"\"\n",
        "        false: The answer is long and difficult to understand.\n",
        "        true: The answer is completely concise, readable and engaging.\n",
        "        \"\"\",\n",
        "    },\n",
        "    {\n",
        "        \"metric\": \"relevant\",\n",
        "        \"rubrics\": \"\"\"\n",
        "        false: The answer is not relevant to the original text, or has significant flaws.\n",
        "        true: The answer is completely relevant to the original text, and provides additional value or insight.\n",
        "        \"\"\",\n",
        "    },\n",
        "    {\n",
        "        \"metric\": \"🥇accurate\",\n",
        "        \"rubrics\": \"\"\"\n",
        "        Compare the factual content of the model's answer with the correct answer. Ignore any differences in style, grammar, or punctuation.\n",
        "        false: There is a disagreement between the model's answer and the correct answer.\n",
        "        true: The model's answer contains all the same details as the correct answer.\n",
        "        \"\"\",\n",
        "    },\n",
        "]\n",
        "\n",
        "    scoring_prompt = \"\"\"\n",
        "    You have the correct answer, original text and the model's answer below.\n",
        "    Based on the specified evaluation metric and rubric, assign a true or false score the summary.\n",
        "    Then, return a JSON object with the metric name as the key and the evaluation score (false or true) as the value. Don't output anything else.\n",
        "\n",
        "    # Evaluation metric:\n",
        "    {metric}\n",
        "\n",
        "    # Evaluation rubrics:\n",
        "    {rubrics}\n",
        "\n",
        "    # Correct Answer\n",
        "    {ground_truth}\n",
        "\n",
        "    # Original Text\n",
        "    {retrieved_chunk}\n",
        "\n",
        "    # Model Answer\n",
        "    {model_answer}\n",
        "\n",
        "    \"\"\"\n",
        "    evals = \"\"\n",
        "    for i in eval_rubrics:\n",
        "        eval_output = predict(scorer_llm,\n",
        "            scoring_prompt.format(\n",
        "                ground_truth=ground_truth, retrieved_chunk=retrieved_chunk, model_answer=answer,\n",
        "                metric=i[\"metric\"], rubrics=i[\"rubrics\"]\n",
        "            ))+\" \"\n",
        "        evals+=eval_output\n",
        "    # evals_json = format_string_to_json(evals)\n",
        "    evals_dict = string_to_dict(evals)\n",
        "    # print(\"___________________________\")\n",
        "    # print(evals_dict)\n",
        "    # print(\"___________________________\")\n",
        "    return evals_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "y4cRBlJt7yLu"
      },
      "outputs": [],
      "source": [
        "# def ragas_score(question, ground_truth, model_output):\n",
        "#     from datasets import Dataset\n",
        "#     from ragas import evaluate\n",
        "#     from ragas.metrics import faithfulness, answer_relevancy, answer_correctness, context_recall, context_precision\n",
        "\n",
        "#     metric_modules = [\n",
        "#         answer_relevancy,\n",
        "#         context_recall,\n",
        "#     ]\n",
        "\n",
        "#     # Convert the retrieved_chunk to a list of strings\n",
        "#     contexts = [str(chunk) for chunk in model_output[\"retrieved_chunk\"]]\n",
        "\n",
        "#     qa_dataset = Dataset.from_dict(\n",
        "#         {\n",
        "#             \"question\": [question],\n",
        "#             \"ground_truth\": [ground_truth],\n",
        "#             \"answer\": [model_output[\"answer\"]],\n",
        "#             \"contexts\": [contexts],  # Wrap contexts in another list\n",
        "#         }\n",
        "#     )\n",
        "#     result = evaluate(qa_dataset, metrics=metric_modules,\n",
        "#                       raise_exceptions=False)\n",
        "#     return replace_nan_in_dict(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "aoqWszGw7yLu"
      },
      "outputs": [],
      "source": [
        "@weave.op()\n",
        "def tonic_validate_score(question: str, ground_truth: str, model_output: dict) -> dict:\n",
        "    from tonic_validate import Benchmark, ValidateScorer\n",
        "    from tonic_validate.metrics import DuplicationMetric, AnswerSimilarityMetric, AnswerConsistencyMetric\n",
        "\n",
        "    metric_modules = [DuplicationMetric(), AnswerSimilarityMetric(), AnswerConsistencyMetric()]\n",
        "\n",
        "    def get_llm_response(question):\n",
        "        return {\n",
        "            \"llm_answer\": model_output['answer'],\n",
        "            \"llm_context_list\": (\n",
        "                [model_output['retrieved_chunk']]\n",
        "                if isinstance(model_output['retrieved_chunk'], str)\n",
        "                else model_output['retrieved_chunk']\n",
        "            ),\n",
        "        }\n",
        "\n",
        "    benchmark = Benchmark(questions=[question], answers=[ground_truth])\n",
        "    scorer = ValidateScorer(metrics=metric_modules)\n",
        "    run = scorer.score(benchmark, get_llm_response)\n",
        "    return run.run_data[0].scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8LnvJEcy7yLu",
        "outputId": "ded90f1c-f90d-4bfc-fc7c-a7fd38b19859"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:weave.trace_server_bindings.remote_http_trace_server:retry_attempt\n",
            "INFO:weave.trace_server_bindings.remote_http_trace_server:retry_attempt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAG Model: meta-llama/Meta-Llama-3-70B-Instruct-Turbo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How is the sense of spaciousness addressed in the design of habitats for the colony?\n",
            "The sense of spaciousness is addressed in the design of habitats for the colony by: \n",
            "\n",
            "1. Providing large-scale vistas to lessen the sense of artificiality.\n",
            "2. Limiting the view so that the entire structure cannot be seen in a single scan.\n",
            "3. Facilitating individual variation through flexible, modular components.\n",
            "4. Providing access to regions of zero gravity and views of the Earth, Moon, and stars.\n",
            "5. Incorporating live, growing things such as vegetation, children, and animals to reduce artificiality.\n",
            "6. Organizing space to minimize the sense of crowding while providing needed services.\n",
            "\n",
            "By incorporating these design elements, the colony's habitats can provide a sense of spaciousness and reduce the negative effects of artificiality.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the steps involved in the process of producing aluminum from lunar soil, specifically in regards to glass grinding and acid leaching?\n",
            "The passage does not mention \"glass grinding\" in the context of producing aluminum from lunar soil. However, it does mention the steps involved in producing aluminum, which are:\n",
            "\n",
            "* Melt-quench-leach production of alumina\n",
            "* High-temperature electro-winning of aluminum from aluminum chloride\n",
            "\n",
            "Additionally, the passage mentions acid leaching as a possible technique for producing glass from lunar materials, but not for producing aluminum. According to the passage, acid leaching could be used to remove non-silicate ingredients from lunar soil to produce high-quality glass.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the importance of atmospheric pressure in large colonies in space?\n",
            "To maintain life processes adequately, the human organism requires an atmosphere of acceptable composition and pressure. The atmosphere of the space habitat must contain a partial pressure of oxygen (pO2) sufficient to provide high enough partial pressure within the alveoli of the lungs.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How does the expense of providing human workers encourage reliance on automation and the push for extreme reliability and maintainability in space commercial ventures?\n",
            "There is no direct answer to this question in the provided context. The text does not mention the expense of providing human workers as a factor in encouraging reliance on automation and the push for extreme reliability and maintainability in space commercial ventures.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are some potential benefits of long-term development in space?\n",
            "According to the text, some potential benefits of long-term development in space include:\n",
            "\n",
            "* Energy independence within 70 years\n",
            "* Low-cost energy that can be used for electrolysis of water to produce transportable fuels, reducing dependence on petroleum products\n",
            "* Widespread application of low-cost electricity to benefit low-income people and developing nations\n",
            "* Communication and Earth-sensing satellites can be improved and expanded with the help of space colonization\n",
            "* Space manufacturing can benefit from lunar resources and cheap solar energy, reducing costs\n",
            "* Return cargo can be carried on rocket traffic that comes to L5 to deliver new colonists and components for SSPS's\n",
            "* Resources from the lunar surface or deep space can be returned to the Earth, reducing the need for mining on Earth and the resulting environmental conflicts\n",
            "* Zero-gravity industry at L5 can be used to fabricate glider-like lifting bodies in space, which can then be launched towards the Earth, reducing environmental impact\n",
            "* Research in deep space can be conducted, allowing for the construction of very large objects, such as radio telescope antennas and optical telescopes, in zero-gravity regions.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the gravities of Jupiter's Galilean moons and Saturn's Titan compared to Earth's Moon?\n",
            "Io: 0.18g, Europa: 0.13g, Ganymede: 0.15g, Callisto: 0.13g, Titan: 0.14g. These are comparable to Earth's Moon, which has a gravity of 0.17g.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What needs to be better understood before evaluating the usefulness of other libration points for space colonies?\n",
            "The cost of station-keeping needs to be better understood before evaluating the usefulness of other libration points for space colonies.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the likelihood of gaseous sub-Neptunes being habitable?\n",
            "There is no direct answer to this question in the provided context. However, it can be inferred that the possibility of life evolving in the cloud tops of giant planets (like gaseous sub-Neptunes) has not been decisively ruled out, though it is considered unlikely, as they have no surface and their gravity is enormous.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How can a metabolism exist outside the classical habitable zone?\n",
            "A metabolism can exist outside the classical habitable zone if it doesn't depend on the stellar light, and instead thrives in the interior of the planet where liquid water is available.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Why do some scientists and experts argue for the colonization of space as a means of saving humanity?\n",
            "According to the text, some scientists and experts argue for space colonization as a means of saving humanity because it could:\n",
            "\n",
            "* Mitigate the impacts of overpopulation on Earth, such as resource depletion\n",
            "* Ensure the survival of the human species\n",
            "* Spread life and beauty throughout the universe\n",
            "* Make money through new forms of space commercialization\n",
            "* Save the environment of Earth by moving people and industry into space\n",
            "\n",
            "Additionally, Nick Bostrom argues that from a utilitarian perspective, space colonization could produce an enormous amount of utility (or happiness) by enabling a very large population to live for a very long period of time.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are some criticisms of space colonization?\n",
            "Some criticisms of space colonization are:\n",
            "\n",
            "* The costs of commercial activity in space are too high to be profitable against Earth-based industries.\n",
            "* The focus on space colonization may enhance the interests of the already powerful, including major economic and military institutions.\n",
            "* A slowdown in population growth rates since the 1980s has alleviated the risk of overpopulation, making space colonization less necessary as a solution.\n",
            "* Changing only the location but not the logic of exploitation will not create a more sustainable future.\n",
            "* Shipping vast numbers of people into space is not a viable solution to human overpopulation on Earth.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the purpose of positioning another spacecraft fueled for a return to Earth in orbit around Mars?\n",
            "To enable the initial crew to eventually return to Earth.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the relationship between propulsive effort and travel time in space travel?\n",
            "The relationship between propulsive effort and travel time in space travel is inverse. According to the text, \"time and effort of transportation are inversely related.\" This means that as travel time decreases, the propulsive effort (or total change in velocity required) increases, and vice versa.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the advantages of the Moon for the space colonization program?\n",
            "According to the text, the advantages of the Moon for the space colonization program include:\n",
            "\n",
            "1. Proximity to Earth\n",
            "2. Lower escape velocity\n",
            "3. Abundant ice trapped in permanently shadowed craters near the poles, which could provide support for the water needs of a lunar colony\n",
            "4. Native precious metals, such as gold, silver, and platinum, are concentrated at the lunar poles by electrostatic dust transport.\n",
            "\n",
            "Note that the text also mentions some challenges and concerns related to the Moon's environment, such as lack of atmosphere, radiation, meteoroids, and low surface gravity.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How could self-replication enable exponential growth in space colonization?\n",
            "Self-replication could enable exponential growth in space colonization by allowing colonies to increase in number without depending on Earth, thereby eliminating costs to and dependence on Earth.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What factors determine the habitability of planets within galactic habitable zones?\n",
            "The habitability of planets within galactic habitable zones is determined by several factors, including:\n",
            "\n",
            "1. Bulk composition\n",
            "2. Orbital properties\n",
            "3. Atmosphere\n",
            "4. Potential chemical interactions\n",
            "5. Stellar characteristics, such as:\n",
            "   - Mass\n",
            "   - Luminosity\n",
            "   - Stable variability\n",
            "   - High metallicity\n",
            "6. Rocky, wet terrestrial-type planets and moons with the potential for Earth-like chemistry.\n",
            "\n",
            "These factors are considered important in determining the habitability of planets and moons within galactic habitable zones.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the difficulties associated with automated rendezvous and interception in the context of the transport system for a lunar colony?\n",
            "The difficulties associated with automated rendezvous and interception in the context of the transport system for a lunar colony are the uncertainties about precision of aim and the propulsion requirements for the interceptor rockets.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How does the design of the space colonization system incorporate existing technology?\n",
            "The design of the space colonization system incorporates existing technology by using solar energy to generate electricity and power solar furnaces to refine aluminum, titanium, and silicon from lunar ores, and by manufacturing satellite solar power stations and new colonies with these materials.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the chosen location for the first space colony?\n",
            "The chosen location for the first space colony is a rotating habitat in satellite orbit around the Earth at a distance of the Moon, specifically at either the Lagrangian point L4 or L5.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What role does critical path analysis play in determining the sequencing of mirror, power plant, shield, and internal construction in the fabrication of space habitats?\n",
            "According to the text, critical path analysis plays a crucial role in determining the best sequencing of mirror, power plant, shield, and internal construction in the fabrication of space habitats, specifically to complete the basic shell and the first layer of shielding as quickly as possible.\n",
            "___________________________\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": false}\n",
            "{\"relevant\": false}\n",
            "{\"accurate\": false}\n",
            "{\"concise\": false}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": false}\n",
            "{\"concise\": false}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": false}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": false}\n",
            "{\"relevant\": true}\n",
            "{ \"accurate\": false }\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": false}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": false}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 6887.20it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dc-b775-7472-9c5b-a1fc1397cedf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dc-ba49-7dd3-ad54-9915df777bf6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dc-be76-7b60-a094-ea5b4c375092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dc-ced6-7df3-96f1-1281097f1ba8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dc-d1c1-79e2-ae65-4d061202abab\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dc-d4cb-75f3-a691-e66ec184bf11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dc-d8de-75a0-b518-235482cb4a8b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dc-dbea-78e0-a217-62810e31e2c0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:11<00:00, 11.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dc-df08-7521-88a8-dba2f6d38ee9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 568.72it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dc-e854-7791-bf07-f38b4ce42241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dc-eabd-7af2-b752-c53d9842b4d0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dc-ecf5-7753-806f-cfa7553246f8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dc-ff4b-7e72-acbd-705a887565e6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-022e-7282-94ae-6bb068ad8861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-04dd-72c1-9ba6-9b7f05c548a4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-07b1-7fd2-8804-520c8d3771c4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-0c98-7892-8908-b7e533c0a33c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:11<00:00, 11.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-1057-7252-99e7-6fb7bd7859ed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 1226.40it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-190a-7231-928f-0449f66ad962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-1b32-73e0-a8fb-ea807ed11a5c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-1d6d-79a2-b6d8-5e9e5b1202c9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-27f9-7bb1-a079-428d7ce7f27a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:05<00:00,  5.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-2af7-77c1-a634-aa3f530d06f9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 752.07it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-33a5-77a2-8c14-cb6b48a58d0f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-35ca-7d40-a1b5-0d7475ffb7d3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-388b-7761-a5af-454a4a570275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-42c4-74d3-bad0-999bfb40fb05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-4786-7c10-a030-5900f2bd8e6c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:07<00:00,  7.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-4afb-7620-854e-03efacb5ddc9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 6775.94it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-54c2-7520-bc50-229294d61b8b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-56c9-7611-9e9f-ec1b5dd7022c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-58e8-79e1-ab64-e87f5ad03b66\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-7885-7661-86bd-5a32e6ca7380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-7b8a-76f0-ac2f-da34dc467121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-7e7f-7060-b807-9c11b3180dbf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-82e7-78a0-b725-457bf663c19f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-85bc-7713-806c-eaeae28c076e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-8893-7a60-9a44-1c08f2055c06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-8b68-7881-9379-f08e5bfa87c8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-8e3a-70f1-a9f5-9b1bee76c34c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:16<00:00, 16.43s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-918b-7a92-8d87-2bb679de7bf8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7584.64it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-9aa8-7763-952b-292764d90f5b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-9d98-7b62-a515-7989a68aa033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-9fa0-7db3-af07-63b59403a895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-aaa5-79a3-a0c5-e24d98974f98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-aec3-7d51-9eed-025530b39ae9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-b21b-7313-a9c0-a1e6a30b2b93\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-b620-7a70-aec3-983c5dd02f98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-bb11-73a3-bc01-06e1dd83f3f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:09<00:00,  9.96s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-be8a-78c0-bc79-0d3ddfcf4ecb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 477.28it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-c6d1-7ef1-96e3-13fdabd54fe0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-c892-7b81-bb3c-3c7307477333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-caac-7210-9406-c9236e23e617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-ce9f-7c60-bb22-7b0e17527b62\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-d1fe-78d0-b1b6-5f69563f3528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:04<00:00,  4.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-d4da-7c91-9031-0343d46029c3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 8630.26it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-dd3b-73e0-8ad3-e8ac0e8f9554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-e2e5-76a0-8263-9e87d36723de\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-e53b-7852-a5ba-d2497f062d96\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-f26d-7ef2-93f5-adb749391791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-f57a-7c40-8bc8-74a1c094b591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-f8e5-7a43-b1e8-b563782bc279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8dd-fd21-7380-a9e9-10a649c80e37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:09<00:00,  9.97s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-001f-71b0-888c-ee780e89fc03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 6316.72it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-0927-7981-9e1e-70adda53dec7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-0bba-7b72-9aa5-6394f003c9b2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-0ee7-7cc1-b693-66335c8a229d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-16b7-7bc0-a443-312e6b94e376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-1b11-7810-bb0c-4e0235d2ab62\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-2749-70c1-bbf8-bb7038eb49a4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:09<00:00,  9.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-2af6-76c0-ae16-905cfb97816d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 4739.33it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-330d-7012-b4c3-fb99b4ed1520\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-36f1-79b1-a6a4-299cff02fd80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-38d0-7451-babb-4b446f003d22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-49e1-7781-b34a-ea8ecb6fd02a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-4cf4-7753-bc38-cc0304db46a0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-5020-7252-9cfe-8ba8587d243b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-5303-7c13-8d84-3c3c61abb4c5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-56d8-79d1-a160-6fc90cdf11c5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:11<00:00, 11.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-5bc4-7761-b08d-8fe0c3cfb789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7084.97it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-649f-7e83-b16d-ac7472fba049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-671d-7643-a44e-cd78a071c65d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-6928-7641-b9ed-fe3f4591667e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-7d9e-7d91-a0f0-009effa8994d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-80b1-7212-818d-5cc30eba268e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-84f3-7201-ad91-063a973bd93a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-8800-7343-b3e0-2f90457622bb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:10<00:00, 10.68s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-8b34-7701-8874-13ef183fdb44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 727.67it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-939d-7c42-a0c6-ffa42cda46ad\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-9537-7ce2-bf98-d9bd359aab09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-9818-70c3-b51b-a5d14dc524db\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:04<00:00,  4.69s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-9c34-7822-af69-f6919b45ba95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7049.25it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-ad58-7e20-971f-e1385a99780f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-ba78-7af2-b9cf-ae91a2da371f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-c144-72e3-b015-dfc750cfa027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-cb6c-7320-bbd4-0f55e58d34d6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-cead-7672-8b00-3e0e555da49c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-d1de-71d3-ba98-981cbe851889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:11<00:00, 11.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-d55e-7a81-905c-87a27e35a230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7256.58it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-ddcf-7ca2-bc40-6c23b8b2e419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-e0b2-7c10-abdd-442fb822009c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-e2a9-7292-b04c-438ef814f450\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-f2d6-78d3-8b25-efbab756aa8b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-f5e8-7592-9741-a3bd80b67348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-f92a-7b40-a087-8a712ea04f9a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:08<00:00,  8.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8de-fcf3-7e72-8505-cec530f83d3e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7256.58it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-056e-7330-8ec9-2be7e522cf35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-076c-7901-b2cd-390e66a46597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-0977-75f3-b490-141e0de0a94f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-0f4a-7db3-9f65-2dfe90cddfd3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-1509-7b72-9820-6aa0fc34b7db\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-1a69-7ee0-ab93-2ee13c920e0c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:07<00:00,  7.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-1df8-7a10-8584-bf5ac3f45368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 458.39it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-268f-7e20-b975-ed32e1bb3d43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-292d-7442-9711-55ff481a35cf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-2b22-7c02-8fc4-0aaf3fefc617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-39ad-7743-bc7f-49459ad602e3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-3e13-73c3-b381-4df8d447e5e6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-42a3-7353-972b-e75093a78cce\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-469e-77d0-b17f-3ece2a4a9cbf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-49ae-7733-ad14-2b29ee1ca1af\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-4cc4-7811-9d75-488c4370767f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-4fa1-75a3-9999-5b80a0d3db9c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-52ca-71c2-a504-7835abafc555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-55df-79f3-9974-e9a68921c8cc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:13<00:00, 13.79s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-58ee-70e1-bf08-47da1c8bed0a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7989.15it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-6226-7331-876a-6eff76f4b5ee\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-645b-7e13-921e-54c9b3be2cbd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-666f-7ec3-9976-266d87c79cd4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-6df9-7ac3-be72-4f8538714e0d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-7115-79e3-b64c-1cc79fe8512f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:05<00:00,  5.49s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-73fa-7923-b2c5-ce4e93117002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7476.48it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-7c8d-79e1-86a1-a9d1dd9b92b2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-80f1-7422-90d2-2c8775bed316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-8305-7490-8f70-a608f5344711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-8ba8-7ca1-997c-c170a219d13f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-8edf-7b13-a857-7206a2e4ff02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-91f6-79d3-9dc3-9ace5e5016ba\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:06<00:00,  7.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-94f6-71f2-9c37-2f62ebe1a3a0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 4510.00it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-9cc0-7f20-9c96-e391a0f4fd8c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-a009-7212-a1a2-d0e0b7724784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-a2e2-74f2-84dc-62aa2a94859d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-acb6-7450-8731-7a7061094255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-afac-7472-bdcd-f63c66cdae08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-b2c1-76a2-8e9a-e854b50b5471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:07<00:00,  7.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-b5cf-76f3-9223-566488bf5e96\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 6909.89it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-bdf0-70c3-804b-98b2ea3a8965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-c0af-7cd0-8f1f-b04815e4815b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-c31e-7b71-9875-5f199e2817db\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-cd4b-7f72-9432-dcde63a095a9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-d081-75c2-a8d0-cd5aaefab2cb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:06<00:00,  6.81s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8df-d3a3-76d0-bc3c-4c0c7f9e6656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:weave.trace_server_bindings.remote_http_trace_server:retry_attempt\n",
            "INFO:weave.trace_server_bindings.remote_http_trace_server:retry_attempt\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the disadvantages of the intense ionizing radiation on the moons of Jupiter for colonization?\n",
            "The disadvantages of the intense ionizing radiation on the moons of Jupiter for colonization are:\n",
            "\n",
            "* Exposure to about 0.75 Sv over a few days is enough to cause radiation poisoning, and about 5 Sv over a few days is fatal.\n",
            "* Radiation levels on Io and Europa are extreme, enough to kill unshielded humans within an Earth day.\n",
            "* Only Callisto and perhaps Ganymede could reasonably support a human colony, as they have lower radiation levels.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Why did Stephen Hawking argue for space colonization as a means of saving humanity?\n",
            "According to the text, Stephen Hawking argued for space colonization as a means of mitigating the impacts of overpopulation of Earth, specifically to alleviate resource depletion.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How does the mass launcher use the principle of the linear induction motor to launch lunar material?\n",
            "The mass launcher uses the principle of the linear induction motor to launch lunar material by accelerating five 10-kg masses of lunar material per second to lunar escape velocity of 2400 m/s using a linear electric motor running the length of the track.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the advantages of locating the colony in large orbits around L4 and L5?\n",
            "There is no mention of locating the colony in large orbits around L4 and L5. The text actually discusses the advantages of locating a catcher at L2 instead of L5, which are:\n",
            "\n",
            "1. L2 is one-seventh the distance of L5, permitting use of either a smaller catcher or a less accurate mass-driver.\n",
            "2. A nearside location for the mass-driver at L2 permits use of knowledge of Moon rocks brought back in Apollo flights and allows for line-of-sight communications to Earth.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are alternative biochemistries and how do they relate to the search for extraterrestrial life?\n",
            "The text does not mention alternative biochemistries. It assumes that extraterrestrial life, if it exists, will be based on the same fundamental biochemistry as found on Earth, involving the elements carbon, hydrogen, oxygen, and nitrogen.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the significance of water availability in determining habitability?\n",
            "Water availability is a crucial factor in determining habitability. Water is a solvent in which biological processes take place and is essential for life's emergence. The vast majority of water necessary for life on Earth likely came from comets impacting the early Earth, providing a kick-start to the origin of life.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the significance of the list of extrasolar planet candidates released by the Kepler Space Observatory Mission team?\n",
            "There is no information in the provided context about the list of extrasolar planet candidates released by the Kepler Space Observatory Mission team. The text appears to be about potentially habitable exoplanets and their characteristics, but it does not mention the Kepler Space Observatory Mission team or the significance of their list.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are some arguments against using space colonization as a solution to human overpopulation?\n",
            "Some arguments against using space colonization as a solution to human overpopulation include:\n",
            "\n",
            "1. Shipping vast numbers of people into space to \"solve\" overpopulation on Earth is physically impractical.\n",
            "2. Changing only the location but not the logic of exploitation will not create a more sustainable future.\n",
            "3. The problem is not the lack of resources in space, but the physical impracticality of shipping people into space to solve overpopulation on Earth.\n",
            "4. The costs of commercial activity in space are too high to be profitable against Earth-based industries.\n",
            "5. A slowdown in population growth rates since the 1980s has alleviated the risk of overpopulation.\n",
            "\n",
            "These arguments suggest that space colonization is not a viable or practical solution to human overpopulation.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are some arguments for and against space settlement?\n",
            "The text does not explicitly provide a list of arguments for and against space settlement. However, it mentions that \"many arguments for and against space settlement have been made\" and cites a reference ([3]) that likely provides more information on these arguments.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the role of electrical supply and distribution in a space colony?\n",
            "There is no mention of electrical supply and distribution in a space colony in the provided context. The text only discusses government, life support systems, food production, waste recycling, atmosphere composition, and solar power satellites, but not electrical supply and distribution.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the proposed trajectory for mankind's expansion into space colonization?\n",
            "The proposed trajectory for mankind's expansion into space colonization involves several steps, including:\n",
            "\n",
            "1. Initial investment: A significant upfront investment is required to establish a human presence in space.\n",
            "\n",
            "2. 50-year development: *The Eros Project* plans a 50-year development period for space colonization.\n",
            "\n",
            "3. Expansion with fewer negative consequences: Space settlement advocates argue that expanding into space can minimize environmental devastation and displacement of indigenous peoples, as space has no known life.\n",
            "\n",
            "4. Alleviating overpopulation and resource demand: By utilizing extraterrestrial resources, demand on terrestrial resources would decline, mitigating the impacts of overpopulation on Earth.\n",
            "\n",
            "5. Establishing self-sustaining habitats: Building viable life-supporting habitats in space would enable humans to thrive and expand in space.\n",
            "\n",
            "Note: This answer is based on the provided context and may not reflect the actual trajectory of space colonization, which may be influenced by various factors and uncertainties.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the purpose of a heavy lift launch vehicle in space colonization?\n",
            "This passage does not mention the purpose of a heavy lift launch vehicle in space colonization.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the advantages and disadvantages of the Bernal sphere as a habitat configuration?\n",
            "Advantages:\n",
            "\n",
            "* Efficient in shielding requirements, needing 300,000 t less than the banded torus and millions of tonnes less than any other configuration.\n",
            "* Supplies exactly the right amount of space for a colony of 10,000.\n",
            "\n",
            "Disadvantages:\n",
            "\n",
            "* Requires from 3 to 4 times as much atmospheric mass as the other possible forms.\n",
            "* Requires from 2 to 4 times as much structural mass as the other possible forms.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What factors affect the economic viability of space colonization for the production of SSPS's?\n",
            "According to the text, the factors that affect the economic viability of space colonization for the production of SSPS's (Solar Power Satellites) include:\n",
            "\n",
            "1. Time horizon of the program: A 70-year extension of the program introduces cost uncertainties and suggests changes in the system that would be likely to increase its economic productivity.\n",
            "2. Sequence of establishing colonies: Building several construction shacks first and then beginning to build SSPS's and colonies at the same time can reduce costs.\n",
            "3. Labor force in space: The size and timing of the labor force in space affect costs, with a smaller force needed initially and a larger force needed later.\n",
            "4. Use of lunar materials: Expansion of the lunar base and production of additional mass drivers can reduce costs.\n",
            "5. Development of a second-generation shuttle system: A new shuttle system with lower operating costs can reduce costs and increase efficiency.\n",
            "6. Market penetration: The rate at which SSPS's penetrate the electricity market affects revenue and costs.\n",
            "7. Market size: The size of the market for electrical energy from space, including both U.S. and foreign markets, affects revenue and costs.\n",
            "8. Cost of electricity: The cost of electricity from SSPS's compared to terrestrial sources affects revenue and costs.\n",
            "9. International funding: An international organization to fund the colonization program could bring greater benefits to terrestrial Americans.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What factors were considered in determining the size and distribution of the population in the space colony design?\n",
            "The factors considered in determining the size and distribution of the population in the space colony design include:\n",
            "\n",
            "* Area per person (at least 40 m^2 of projected area per inhabitant)\n",
            "* Population density and sense of crowding\n",
            "* Availability of services and facilities provided to the inhabitants\n",
            "* Organization of space to minimize the sense of crowding\n",
            "* Providing private exterior space, pedestrian access space, and public open space\n",
            "* Allocation of space for various purposes such as residential, commercial, public and semipublic enclosed space, light service industry, wholesaling and storage, mechanical subsystems, transportation, and agriculture.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are some proposed models of transplanetary or extraterrestrial governance in the context of space colonization?\n",
            "According to the provided context, some proposed models of transplanetary or extraterrestrial governance in the context of space colonization include:\n",
            "\n",
            "* The Outer Space Treaty, which establishes that outer space is not subject to national appropriation by claim of sovereignty and shall be carried out for the benefit and in the interests of all countries.\n",
            "* The concept of \"common heritage of humanity\", which implies that outer space and its resources are shared by all humanity.\n",
            "* The Moon Treaty, which is a less ratified international agreement that aims to regulate the use of the Moon and its resources.\n",
            "* National laws, which are developing to regulate space activity and colonization.\n",
            "\n",
            "No other specific models of governance are mentioned in the provided context.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What role did NASA play in determining the habitability of KOI-1686.01?\n",
            "NASA proved KOI-1686.01 to be a false positive in 2015.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the effects of isolation in closed environments on the mental and emotional health of colonists in space colonization?\n",
            "According to the text, isolation in closed environments aboard the International Space Station led to depression, sleep disorders, and diminished personal interactions, likely due to confined spaces and the monotony and boredom of long space flight.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the characteristics of TOI-700_d?\n",
            "According to the table, the characteristics of TOI-700_d are:\n",
            "\n",
            "* Host star: TOI-700 (M2V type)\n",
            "* Mass: ~1.72\n",
            "* Radius: 1.14\n",
            "* Distance: 246\n",
            "* Temperature: 37.4\n",
            "* Orbital period: 101\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m6\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m7\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m8\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m9\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m10\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m11\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m12\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m13\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m14\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m15\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m16\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m17\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m18\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m19\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How is a solar furnace used in the production of aluminum from lunar soil?\n",
            "A solar furnace is used to generate high temperatures in the production of aluminum from lunar soil. Specifically, it is used in the melt-quench-leach production of alumina, which is then followed by high-temperature electro-winning of aluminum from aluminum chloride.\n",
            "___________________________\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": false}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": false}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": false}\n",
            "{\"accurate\": false}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{ \"accurate\": true }\n",
            "{\"concise\": false}\n",
            "{\"relevant\": false}\n",
            "{ \"accurate\": false }\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": false}\n",
            "{\"relevant\": false}\n",
            "{\"accurate\": false}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": false}\n",
            "{\"accurate\": false}\n",
            "{\"concise\": false}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": false}\n",
            "{\"relevant\": false}\n",
            "{\"accurate\": false}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": false}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": false}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m20\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 763.16it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-0652-7673-9f58-f5f6b243c820\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-08b0-7b50-a567-82dfc7bf527d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-0af8-73c2-b773-7db343449e0a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-1567-7e32-a2b8-50d1aea29000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-2217-7112-b132-6b59ef9acfbb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:09<00:00,  9.80s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-252b-7e11-9cbc-d3b968789681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 716.12it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-31b5-7520-bb86-003527570a55\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-3361-73f3-add8-534258fc3eb3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-3685-7892-aaa0-01da97f904e1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-3c2a-7321-83be-8fc0e3283413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-3f05-7e30-b245-84a4603031ff\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:05<00:00,  5.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-4249-7071-ac7b-655f87f88220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7037.42it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-4b72-7692-a03b-4d61f51c25db\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-4f53-7ce0-927d-8d615c8a5896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-521e-73e0-917e-6c957b1c703d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-5d81-7ee3-9679-4d013b9b59a6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-60a9-7203-a6d9-6716fc1cf867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-6372-71a1-b847-22adca0cedf3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:08<00:00,  8.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-6672-7473-ba3a-1fb69fbd6344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 6689.48it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-712c-7571-9b58-ad8f871ca3cf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-7331-7291-8d7e-c0e42207713d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-7515-7ac3-a177-78eeb3701d04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-8456-7552-83d2-4cc74b963c14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-8808-7770-8890-ff023ef07df3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-8b38-7b12-993b-cfb4c69fe87e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:08<00:00,  8.70s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-903e-7940-86cb-b7beb8548372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7436.71it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-98ee-77e2-9d07-f8da4d233312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-9ac8-74a1-8ffc-affe531efa83\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-9d37-7360-aebe-7d39abe373f8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-a589-7520-bf10-d3d7c5a24e4b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-a8c0-7ff1-83d6-347cde0d8a86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:06<00:00,  6.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-abde-78b1-a81a-d44730a76028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 733.65it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-b5c0-7290-b609-e9b291e53f63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-b7c9-7281-b234-adae565ddf00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-b9c3-7761-8e91-ea3181415909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-c4cf-7983-81ef-cb2b31712919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-c7b6-77d0-b3b1-46c3ea51dbcf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-ca96-7291-9089-f7108c6d0ac3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:06<00:00,  6.93s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-cde7-7d71-a78f-011b5addfa3b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 8322.03it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-d5e4-7340-acc7-43dde50bc7a2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-d83e-7d50-8ff3-a5a429856a46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-da80-7e91-88c8-47ceee2dafe3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-e3bc-73b0-8f04-5c6eeb3c586c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-e700-7e11-8d64-4089ec1bd168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:06<00:00,  6.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-ea26-7152-95b8-24efecacec35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7423.55it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-f27a-72e0-bbea-8ec2c57c2f28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-f53e-7811-ad3b-c4112e593b75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e3-f958-7273-a2e8-bdfd6047250f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-0a7d-7030-98a9-610423a08896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-0d7e-7961-beb8-74d0c13c4e06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-12bc-7002-ae42-a283645496eb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-1595-7300-9273-986d45bff8ab\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:10<00:00, 10.61s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-18d0-7551-a6ef-ad65aadc9467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7530.17it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-215b-76d3-9f15-9a180f8653f6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-2356-7430-a8d5-eb4ca9e403a8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-2547-7be3-86a2-7da2f4f9f88d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-2ddb-7691-a754-b9d201e192ef\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-31d7-7ce1-bb92-598694370740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:05<00:00,  5.90s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-34f4-7550-aac1-befefd7da98d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 1463.98it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-3dbb-7fe0-90fb-24d7988c2254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-3fe5-7732-92ea-a81369c5e332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-4290-7af0-89a5-212d76c137cd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-4a9d-7700-8896-ad6580f33e0b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:04<00:00,  4.82s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-4d6f-7243-ba50-7419176d9e67\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 724.40it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-558c-72c3-8a17-5e831fe08696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-57cc-71b0-ac93-a6a217513fa5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-5a55-7b30-9a22-137a8f340f24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-6ba0-7953-aed2-40da7512689e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-703c-7410-8dd9-ac75aa85cf57\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-7359-70d3-893d-008638f9b605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-7663-7480-b49c-c3f823db5428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:10<00:00, 10.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-7965-7e73-bd0d-b68a6cf5ba6b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 790.48it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-81b0-70a1-b5a5-c04cbae959e9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-837e-7302-9f83-b9d44b337812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-8626-7043-9a50-010a6a28a66d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:03<00:00,  3.14s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-8b3d-75c3-99a7-4a20ba2b3d16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7436.71it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-92de-7a91-808e-5c40d379fe58\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-94f3-7133-b7cb-8655eeee47b0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-96ea-74a0-9f5a-b493df8c25a8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-a43a-7590-b683-7dd12f1ea33a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-a790-7553-9aee-b7fe3e45f448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-ab04-7a60-b244-ac86885dbc9a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:07<00:00,  7.95s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-aecc-7c41-8830-d4c5acdcaba0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 753.02it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-b70c-7cf3-b37e-4c2e2d33c900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-b930-7d31-b861-6f9555225bd2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-bb4d-7cf3-955f-7a3538606b42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-dcee-7352-b0a6-757e962ed110\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-e034-7f70-a40e-7204fd52a064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-e34a-78d3-b907-9e7dce872102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-e8ed-7ad2-8f2c-5947a48f1ed0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-ec10-7310-b6fa-56cc247af51c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-ef40-7fd1-8d9c-2f9a64999ed3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-f290-7782-ac8f-a3913f4c9461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-f60c-7af0-9c22-16b7b902e55a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:17<00:00, 17.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e4-f92b-70f2-b03b-30e15a6bee5d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7724.32it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-01ec-7c83-bd3a-93aa393d83c0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-04be-71c0-910a-42e7599ffc32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-06e6-70c1-a0d2-44f8f6e17dc0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-168c-7622-bd83-fa931d633f44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-1995-74f3-a14b-347d80c96212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-1d6c-72e2-8360-984f43d0d0bb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-212a-76c3-b874-f63fa3bf70cc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-23f5-7c53-a25f-50ed6b16b0dd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:10<00:00, 10.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-26bb-7923-a182-64cdce87ebb3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 1548.86it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-2f13-7633-aab9-a3796185b597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-31da-7d10-b264-9e79e6d412fd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-355d-75a1-bd59-f8a1497fce7f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-4499-7ce0-82c9-878226f6fac4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-4794-7a53-9c1f-d21ccf2e0ea3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-4aac-7732-b815-c95957609bd8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:08<00:00,  8.83s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-4e7f-7630-9081-56d631fe1ec9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 8355.19it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-56b7-7e22-9ea3-a60651cc7267\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-58dc-7691-9083-ff691dcd085d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-5ad2-7342-8641-6ecb5ddd98b7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:03<00:00,  3.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-5f33-72d0-86da-182382f6ed15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 1585.15it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-67f7-7522-afe8-5f8258aa2d98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-6a89-7da0-ab03-16ac1f646d6d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-6da5-7911-9107-b393e218cfe2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-7805-76d1-bc78-2a1abd43509a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-7d33-7eb2-8317-66efb758d59e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-8011-7121-96c5-b16f1737b840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:07<00:00,  7.80s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-8371-7ce0-aea1-73f5db2397e3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7557.30it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-8b58-7af2-93d1-426ffa7c901e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-8d9b-7302-82e9-ee633afb1378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-8fcb-7052-94c9-9d7e3c42814d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-9995-78a1-a4db-464f78299b8e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-9f91-7ef2-8dd4-cbdd2aca9066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-a35d-7c13-a4de-e0815135a079\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-ab33-7b92-b686-924b72b87de9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-aec2-7cc1-8185-291597e40f6b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:10<00:00, 10.80s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-b1e2-7161-b0d9-5c14a84e24dd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 6678.83it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-bae0-7f63-954b-92e67635e8a7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-bd43-7181-a7ff-3855967a8fc1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-c126-7090-8afb-2120f62ab7a6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-caa0-7390-bbc3-e8447a7f2d2e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-cd57-74a2-9f58-152b3da59163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-d0d6-7b23-9a40-a7bfc80b00e6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-d3ef-7740-ae89-037c7ba27c09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-d70f-74e2-882e-073ac4c70f29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-db32-7f61-a158-6cca398e987b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:09<00:00,  9.90s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e5-dea8-7a43-9932-02fbfae3a9c8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:weave.trace_server_bindings.remote_http_trace_server:retry_attempt\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the psychological challenges faced by astronauts during prolonged space missions?\n",
            "According to the provided context, the psychological challenges faced by astronauts during prolonged space missions are not explicitly mentioned. However, it is implied that providing for psychological and esthetic needs of the colonists is important, but the focus is on the physiological effects of living in space.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How does volcanic activity affect the colonization potential of the Saturnian moons?\n",
            "The text does not mention how volcanic activity affects the colonization potential of the Saturnian moons. It only mentions volcanic activity in the context of Io, a Jovian moon, and its hostile environment making it less ideal for colonization.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What factors limit the habitability of exoplanets around red dwarf stars?\n",
            "According to the text, the factors that limit the habitability of exoplanets around red dwarf stars include:\n",
            "\n",
            "1. The small size of red dwarf stars, which means they emit very little light.\n",
            "2. The need for planets to orbit very close to the star to attain Earth-like surface temperatures, which can lead to tidal locking.\n",
            "3. The star's gravity causing tidal locking, resulting in one side of the planet eternally facing the star and the other side always facing away from it.\n",
            "4. The requirement for a thick atmosphere to transfer the star's heat from the day side to the night side, which could prevent sunlight from reaching the surface, making photosynthesis impossible.\n",
            "5. Flares from the star, which could greatly reduce the habitability of exoplanets by eroding their atmosphere.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the significance of solar power satellites in the design for space colonization?\n",
            "Solar power satellites (SPS) could provide a low-cost, benign, and efficient source of energy for space colonization. They would use wireless power transmission to send power to locations on Earth, the Moon, or other locations in space, with zero emissions and minimal ground area required. Additionally, SPS could be built primarily from lunar or asteroid-derived materials, making them a more economic option than traditional fossil fuel or nuclear energy sources.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the chosen method for refining aluminum from lunar anorthosite?\n",
            "The chosen method for refining aluminum from lunar anorthosite is melt-quench-leach production of alumina followed by high temperature electro-winning of aluminum from aluminum chloride.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How does the expense of providing human workers encourage reliance on automation and push for extreme reliability and maintainability in space commercial ventures?\n",
            "The text does not directly answer this question. It mentions automation as a potential future development that could drive the progress of space colonization, but it does not discuss how the expense of providing human workers would encourage reliance on automation.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the suggested advantageous locations for colonization according to Robert Zubrin?\n",
            "According to Robert Zubrin, the suggested advantageous locations for colonization are Saturn, Uranus, and Neptune, due to their atmospheres being good sources of fusion fuels, such as deuterium and helium-3.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the chief assumptions about habitable planets in terms of their characteristics?\n",
            "The chief assumptions about habitable planets are that they are:\n",
            "\n",
            "1. Rocky, terrestrial-type planets and moons\n",
            "2. Have the potential for Earth-like chemistry\n",
            "3. Located in the habitable zone of their star\n",
            "4. Have liquid water available\n",
            "5. Have a stable and suitable atmosphere\n",
            "\n",
            "These assumptions are based on the study of Earth and the conditions that support life on our planet.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How has space colonization been discussed as a continuation of imperialism and colonialism?\n",
            "Space colonization has been discussed as a continuation of imperialism and colonialism, with critics arguing that it perpetuates the narrative of exploration as fundamental to human nature, ignores social inclusiveness, and primarily benefits wealthy elites affiliated with private corporations.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are some criticisms of space colonization?\n",
            "Some criticisms of space colonization include:\n",
            "\n",
            "1. Costs of commercial activity in space are too high to be profitable against Earth-based industries.\n",
            "2. It may not alleviate the problem of human overpopulation, as population growth rates have slowed down since the 1980s.\n",
            "3. Changing only the location but not the logic of exploitation will not create a more sustainable future.\n",
            "4. The forthcoming colonization and commodification of the cosmos may enhance the interests of the already powerful, including major economic and military institutions.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m21\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m22\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m23\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m24\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m25\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m26\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m27\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m28\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m29\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m30\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m31\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m32\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m33\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m34\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m35\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m36\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m37\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"concise\": false}\n",
            "{\"relevant\": false}\n",
            "{\"accurate\": false}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": false}\n",
            "{\"accurate\": false}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concisie\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": false}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m38\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">38</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m39\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">39</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m40\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 760.53it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e6-8b67-71a0-ab91-160c8bd4181d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e6-8d7f-79e3-8519-7c38c18126d6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e6-9096-7413-a761-b5237d9d9545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e6-9b55-7ac1-bea3-5b9a7dbf6013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e6-9fc9-7940-919e-8003c81189a9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:07<00:00,  7.24s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e6-a295-7242-995b-f9ba3d768fa8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7219.11it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e6-accd-7a33-9454-833e8ba0d1e4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e6-af15-7242-a602-6d9d111a0f79\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e6-b10f-7392-ba42-f18c5fa5c1eb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e6-c15c-7802-b139-181861e168a0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e6-c45d-7820-9be8-c4dac4be3e89\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:07<00:00,  7.69s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e6-c7a8-73f3-9256-2105ac45af6d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 735.46it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e6-cfe5-7721-82ca-2930ddafb44a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e6-d3c1-7c32-94f7-e0a00bae93a5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e6-d615-7982-8250-dac247bc1b86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e6-e93b-7050-885f-51bce1742d94\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e6-ec3c-78a0-af36-a54a4259a06c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e6-ef51-7160-83a2-9148d5342bff\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e6-f3fe-7eb1-82e0-5342fb4e0d70\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:11<00:00, 11.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e6-f6c8-7073-b0b8-f1ad1a94de18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 450.76it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-002e-71b2-80e2-f10a701d9f99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-0239-7ac3-91b9-2143477fad9d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-04e7-7761-9a41-7fba4fa90b5b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-156d-7d10-b90e-5bb152a8d933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-1931-7513-9d13-a09db8f0440b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-1fd3-7f40-8c7b-c560094759b3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-22b8-7e51-86ef-34b75cfcded9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:10<00:00, 10.45s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-2636-78f2-aa4b-3779f457b268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 781.64it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-2e2b-7562-9aae-16bc962175b8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-301c-71b1-88d8-054cb8a7f2c2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-328d-7b51-bd27-823e40f87cff\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-3ad1-7cd0-be0b-4415cfb82cc6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-3dd3-7aa2-adef-6e9b6899411b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-409b-7183-817d-be34e09cb565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-4345-78a3-acdf-4b19e62182e8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:07<00:00,  7.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-4686-72b0-bbd3-e3e49a6e7452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 6594.82it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-4ef2-71f3-9ac9-1d6898294515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-50d6-7a12-a521-9cbb8e1c8ed9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-5321-7a53-967d-ffdc1992bd97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-5c0c-7b61-8062-b1829a8e145f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-5f56-70b2-b7b1-48c4ffed8b1c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-6236-77a0-88d1-fe227cb07cf2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:06<00:00,  6.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-64fb-7fa0-b2d8-13f16e5d0904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 1515.28it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-6d28-74c2-b9c5-a69ca3d1e3fc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-6fb7-7a21-924a-f666a2f328ea\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-721b-7eb3-9e76-efed31eb81b9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-7b65-72b3-81e2-2a3a093f73de\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-7e63-7762-8a2f-3c2fe796ed4a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:06<00:00,  6.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-816f-7713-a086-fe5981c69d91\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7767.23it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-8a11-7bc3-bcef-c98947dda4eb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-8fbc-7700-95f7-806100bd9a6d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-9225-74f0-89f1-e7adc2c563e1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-9cb1-7430-b519-0c2d00b483ed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-9fac-7043-88d7-009893834ae5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-a2c9-7f72-a90f-ac390c3f0dc3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-a67f-74b0-b2c3-169937953b30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:08<00:00,  8.90s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-a9a5-74a2-a2c2-8d47aafd1280\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 775.86it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-b211-7bd1-930b-57453959ac21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-ba05-76a0-b49b-7b4e82797011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-bd58-7c32-be31-46aeb7e35a7b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-c7b5-75a1-9bf1-793b0cbb7392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-cda5-7c80-ac6b-ffae10e9f815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-d2f0-7423-90f3-d75167f47f98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:10<00:00, 10.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-d732-7683-a383-cb2d59043de9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 614.01it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-dfa6-7d12-94e6-45319ca39783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-e1d2-7b52-a2c2-137b96165775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-e403-7bd3-9534-091bd6f80c2f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-f2f2-71f1-9303-b77be251bc07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-f628-7611-a4a3-efd5426fd136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-f904-73e1-a950-1414d55827bb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:08<00:00,  8.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e7-fc1b-7521-8701-1d0f4e7e1690\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m41\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m42\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m43\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m44\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">44</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m45\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">45</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m46\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m47\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m48\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m49\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m50\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation summary\n",
              "\u001b[1m{\u001b[0m\n",
              "    \u001b[32m'llm_judge_scorer'\u001b[0m: \u001b[1m{\u001b[0m\n",
              "        \u001b[32m''\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m1.0\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'relevant'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m42\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.84\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'concise'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m36\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.7346938775510204\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'accurate'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m35\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.7142857142857143\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'concisie'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m1.0\u001b[0m\u001b[1m}\u001b[0m\n",
              "    \u001b[1m}\u001b[0m,\n",
              "    \u001b[32m'tonic_validate_score'\u001b[0m: \u001b[1m{\u001b[0m\n",
              "        \u001b[32m'answer_consistency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.845952380952381\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'duplication_metric'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.1\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'answer_similarity'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m3.08\u001b[0m\u001b[1m}\u001b[0m\n",
              "    \u001b[1m}\u001b[0m,\n",
              "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m96.81406387329102\u001b[0m\u001b[1m}\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
              "<span style=\"font-weight: bold\">{</span>\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'llm_judge_scorer'</span>: <span style=\"font-weight: bold\">{</span>\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">''</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'relevant'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.84</span><span style=\"font-weight: bold\">}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'concise'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7346938775510204</span><span style=\"font-weight: bold\">}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'accurate'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7142857142857143</span><span style=\"font-weight: bold\">}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'concisie'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">}</span>\n",
              "    <span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'tonic_validate_score'</span>: <span style=\"font-weight: bold\">{</span>\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'answer_consistency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.845952380952381</span><span style=\"font-weight: bold\">}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'duplication_metric'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span><span style=\"font-weight: bold\">}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'answer_similarity'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.08</span><span style=\"font-weight: bold\">}</span>\n",
              "    <span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">96.81406387329102</span><span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8d9-9b88-7363-b5a3-3426698ec683\n",
            "RAG Model: meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How is the sense of spaciousness addressed in the design of habitats for the colony?\n",
            "To address the sense of spaciousness in the design of habitats for the colony, several approaches are considered:\n",
            "\n",
            "1. Providing large-scale vistas: Making the habitat large enough to reduce the sense of artificiality. \n",
            "2. Limiting a colonist's view: Designing the habitat so that parts of it are always out of sight of others, reducing the claustrophobic feeling.\n",
            "3. Incorporating natural elements: Providing live, growing things like plants for decoration and pets to bring a sense of organic feel.\n",
            "4. Creating flexible, manipulatable architecture: Allowing colonists to change and exploit spaces according to their needs and preferences.\n",
            "5. Providing open spaces: Including parks, outdoor recreation areas, and other open spaces to give individuals a place to escape the pressure of crowds and enhance the sense of spaciousness.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the steps involved in the process of producing aluminum from lunar soil, specifically in regards to glass grinding and acid leaching?\n",
            "According to sections 14 and 17, the steps for producing aluminum from lunar soil involve the following process for aluminum, after glass making for windows, this process is separate from glass production:\n",
            "\n",
            "1. **Aluminum oxide (Al2O3) extraction from anorthosite**: Only Al2O3 is considered worth detailed consideration after quick analysis of the other metal oxides in the ore.\n",
            "2. **Melt-quench-leach production**: This is the chosen system for Al2O3 extraction.\n",
            "3. **Leaching with acid**: This is one of the possible techniques for glass production (stated in the context for glass production in point 17).\n",
            "\n",
            "The former process (melt-quench-leach) is illustrated in chapter 4, figure 4-12 and further information is provided in this and in appendix I.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the importance of atmospheric pressure in large colonies in space?\n",
            "Adequate atmospheric pressure is crucial for human life in space to maintain life processes adequately. It requires a partial pressure of oxygen sufficient for good respiration yet low enough to avert losses in blood cell mass and changes in the number and distribution of micro-organisms.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How does the expense of providing human workers encourage reliance on automation and the push for extreme reliability and maintainability in space commercial ventures?\n",
            "Automation and push for extreme reliability and maintainability in space commercial ventures may increase as the expense of providing human workers is high, making it less cost-effective to maintain a workforce in space. This could drive the development of more automated systems and reduce reliance on human intervention.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are some potential benefits of long-term development in space?\n",
            "Progress in automation and the reduction to normal engineering practice of materials technology now in the laboratory are expected to occur and drive the later stages of space colonization more rapidly and on a larger scale than anticipated. Additionally, inventions that have not yet been foreseen may also contribute to this accelerated development.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the gravities of Jupiter's Galilean moons and Saturn's Titan compared to Earth's Moon?\n",
            "Io - 0.18g, \n",
            "Europa - 0.13g, \n",
            "Ganymede - 0.15g, \n",
            "Callisto - 0.13g, \n",
            "Earth's Moon - 0.17g and \n",
            "Titan - 0.14g.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What needs to be better understood before evaluating the usefulness of other libration points for space colonies?\n",
            "The cost of station-keeping.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the likelihood of gaseous sub-Neptunes being habitable?\n",
            "The likelihood of gaseous sub-Neptunes being habitable is low. They are considered poor candidates for life due to their smaller size and lower gravity, which makes it difficult to retain an atmosphere. They also lack a surface, which is a crucial factor for life as we know it.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How can a metabolism exist outside the classical habitable zone?\n",
            "A metabolism that does not depend on stellar light can exist outside the classical habitable zone, thriving in the interior of the planet where liquid water is available.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Why do some scientists and experts argue for the colonization of space as a means of saving humanity?\n",
            "They argue that it would enable a very large population to live for a long time, possibly billions of years, producing an enormous amount of utility or happiness.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are some criticisms of space colonization?\n",
            "Criticisms of space colonization include: \n",
            "\n",
            "- The costs of commercial activity in space are too high to be profitable against Earth-based industries. \n",
            "- The forthcoming colonization and commodification of space is likely to enhance the interests of the already powerful, including major economic and military institutions.\n",
            "- Population growth rates have slowed since the 1980s, alleviating the risk of overpopulation.\n",
            "- Changing only the location but not the logic of exploitation will not create a more sustainable future.\n",
            "- Shipping vast numbers of people into space to solve overpopulation is impractical and unfounded.\n",
            "- High costs of initial investment and a long period to return on investment.\n",
            "- The risks of impacting native life on extraterrestrial bodies, making the negative consequences of space colonization non-negligible.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the purpose of positioning another spacecraft fueled for a return to Earth in orbit around Mars?\n",
            "To enable the initial crew to eventually return to Earth.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the relationship between propulsive effort and travel time in space travel?\n",
            "Effort and time are inversely related in space travel.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the advantages of the Moon for the space colonization program?\n",
            "The Moon has several advantages for the space colonization program: \n",
            "\n",
            "1. Proximity to Earth: The Moon is relatively close to Earth, making transportation and communication easier.\n",
            "2. Abundant ice: The lunar poles have permanently shadowed craters with ice, which could provide water for human consumption and life support.\n",
            "3. Native precious metals: Gold, silver, and probably platinum are concentrated at the lunar poles, making them a valuable resource.\n",
            "4. Initial intermediate: Establishing a Moonbase can serve as an intermediate step before sending humans to Mars.\n",
            "5. Potential resources for space missions: The Moon's resources and gravitational properties can be leveraged for further space missions and scientific research.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How could self-replication enable exponential growth in space colonization?\n",
            "Self-replication in space manufacturing could enable exponential growth in space colonization by allowing the creation of new equipment, tools, and habitats without the need for constant resupply from Earth. This would reduce costs and dependence on Earth, allowing for a faster expansion of colonies.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What factors determine the habitability of planets within galactic habitable zones?\n",
            "Liquid water, [stellar radiation](https://en.wikipedia.org/wiki/Stellar_radiation), stellar environment (plasma), geophysical, and geodynamical aspects.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the difficulties associated with automated rendezvous and interception in the context of the transport system for a lunar colony?\n",
            "Difficulty associated with automated rendezvous and interception in the context of the transport system for a lunar colony are: precision of aim, difficulties of automated rendezvous.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How does the design of the space colonization system incorporate existing technology?\n",
            "The design of the space colonization system incorporates existing technology by utilizing lunar ores for construction and solar energy generation, building on earlier concepts and research, such as Gerard O'Neill's rotating habitat and solar power stations, and previous ideas from scientists like Robert Goddard, Hermann Oberth, and Wernher von Braun, to create a self-sustaining community in space that meets the specified design goals and requirements.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the chosen location for the first space colony?\n",
            "The chosen location for the first space colony is the Lagrangian point L5, according to the design study of Gerard O'Neill and students at Princeton University.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What role does critical path analysis play in determining the sequencing of mirror, power plant, shield, and internal construction in the fabrication of space habitats?\n",
            "Critical path analysis is used to determine the best sequencing of mirror, power plant, shield, and internal construction to complete the basic shell and first layer of shielding as quickly as possible, allowing for spin-up, gravity simulation, and the initiation of life support functions within the habitat.\n",
            "___________________________\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\":false}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": false}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": false}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": false}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/models.py\", line 820, in generate\n",
            "    yield from self.raw.stream(chunk_size, decode_content=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/response.py\", line 1057, in stream\n",
            "    yield from self.read_chunked(amt, decode_content=decode_content)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/response.py\", line 1206, in read_chunked\n",
            "    self._update_chunk_length()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/response.py\", line 1136, in _update_chunk_length\n",
            "    raise ProtocolError(\"Response ended prematurely\") from None\n",
            "urllib3.exceptions.ProtocolError: Response ended prematurely\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 371, in predict_and_score\n",
            "    result, score_call = await async_call_op(score_fn, **score_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 56, in llm_judge_scorer\n",
            "    eval_output = predict(scorer_llm,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 14, in predict\n",
            "    for chunk in completion:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 153, in <genexpr>\n",
            "    return (ChatCompletionChunk(**line.data) for line in response)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 624, in <genexpr>\n",
            "    return (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 91, in parse_stream\n",
            "    for line in rbody:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/models.py\", line 869, in iter_lines\n",
            "    for chunk in self.iter_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/models.py\", line 822, in generate\n",
            "    raise ChunkedEncodingError(e)\n",
            "requests.exceptions.ChunkedEncodingError: Response ended prematurely\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"concise\": false}\n",
            "{\"relevant\": false}\n",
            "{\"accurate\": false}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\":true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{ \"accurate\": true }\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": false}\n",
            "{\"relevant\": false}\n",
            "{\"accurate\": false}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": false}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the disadvantages of the intense ionizing radiation on the moons of Jupiter for colonization?\n",
            "The intense ionizing radiation from Jupiter's magnetosphere delivers hazardous levels of radiation to the Jovian moons. On Io, it delivers about 36 Sv per day, and on Europa, it delivers about 5.40 Sv per day. Exposure to about 0.75 Sv over a few days can cause radiation poisoning, and about 5 Sv over a few days is fatal.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 756.41it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ea-bb13-7543-b7cd-c1323189b161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ea-bd7a-7fe2-84b2-e8658e1cc28f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ea-bf62-7d70-9e61-723927bed587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ea-d355-78a3-b113-07c788c99c4c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ea-d658-7bb1-9142-8903ed1b7a30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ea-d92b-7452-a2b4-420075066e95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ea-dcb4-73e0-80a5-cbd5addf6360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:10<00:00, 10.52s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ea-e099-7201-ba80-a37a1a856a4e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7410.43it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ea-e987-7e50-b78a-ee49bab67a46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ea-eb95-7c93-9531-1ada001cf76a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ea-ed96-7550-add3-3bf1655c10f4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ea-f2a7-7803-a2ca-ca5b324bd230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ea-f792-7c13-bdb4-d91fa312ad26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:05<00:00,  5.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ea-fabb-7291-b402-eaa0ba4daff7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 8272.79it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-02cc-7bd0-9dd5-7ef16abb6a32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-069b-73e3-ab3f-748b2917d097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-088c-7582-aa84-bea00d9f861f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-12c0-7a81-be93-8d00d3c7a8fe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-1581-7f91-ad0c-2a6d12e8c5d6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-1890-7f02-ab63-fd982339684b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-1b82-7220-ab00-d893a4daf92c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:08<00:00,  8.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-1f61-7a11-a7a3-cebe04e80276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 1651.30it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-2774-7732-922b-299c3bbe18a8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-29de-7f63-a338-5cd09c6da8ec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-2bb9-7392-ade5-8cd87241c9cd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-353c-77f3-8494-9dc6eb684697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-382b-7f00-b71c-4bd680230ea8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-3b0d-7362-8bb1-7c054882c385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:06<00:00,  6.71s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-3e3b-7b40-8328-ce1523ae4b68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 735.97it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-4728-7a23-9ae0-fa58487ba37f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-4929-7490-86ae-3ed705918f9d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-4b40-7603-adbc-adaa317c774b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-53c0-7eb3-834c-a2ad257ef047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:04<00:00,  4.69s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-5666-7061-ae68-f44a8d3170d9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 773.43it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-5e96-7f01-ab86-a392d96f20f2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-6071-7700-9f69-756f84f493c6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-64a1-7222-834e-efccf56d7e61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:03<00:00,  3.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-66d3-7bd1-978d-86716d3ccc19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 1588.75it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-70e0-71a0-a732-db8dc945a547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-7342-7bc1-a632-9b31bade9c93\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-755a-7ea1-86e1-03d5b3b39513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-803a-7832-866e-739dc1bf9d8b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-82fc-74b3-a611-fe1ef05aad68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-85fc-7fe2-a034-c4903ae86c27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:07<00:00,  7.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-88cb-7f91-a861-48b4a8ffd607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 5698.78it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-91ac-79c3-93ff-6a5390bf11ea\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-93bc-7f81-b874-0c2399c0194d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-9601-7df2-bffe-aed0abf8663f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-9bd1-7ac2-b860-dd1ee4130a77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:04<00:00,  4.92s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-9f30-7963-bb34-1d0fe0b3a465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 780.34it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-a9f8-7383-9b02-902669b42552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-abfe-7131-ad6f-ca500bf83044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-ae04-72c2-8ac5-a7b4886dab67\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-b3c9-7d81-a6eb-5f04a909d22d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:05<00:00,  5.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-bb1e-7b01-9089-6078b430ec70\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 8774.69it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-c326-7313-9686-036aeb75c859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-c547-74c2-bae1-1896f4c1781a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-c799-7df1-b36e-fa3b5bee700f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-da2f-7683-9768-f620880aa320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-dd11-79b0-bafd-0456b08d3552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-dfd7-7421-96b7-2dd3858989bf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-e312-7893-bad2-6118e38a79de\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-e5d3-7fb3-a469-3effc01ad523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-e8e7-7741-a6b6-82b19714e659\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:11<00:00, 11.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-ebab-7df1-b88e-ef23fb06d286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 774.86it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-f43f-7491-9433-2897582f373e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-f627-7522-8622-0276850b18f7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-f83b-77c1-a70e-5840c67d6ba8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:02<00:00,  2.62s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8eb-fb1b-7180-bfc9-5c1f7e061c6d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 2283.24it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-03b0-7d31-b1b0-f845c7e61b3b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-0598-7cc3-bc15-a1e66ac1b111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-07e1-7802-a9e5-53c9e26c2357\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:02<00:00,  2.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-0add-7f30-a2bf-2d39b0f41838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 551.81it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-12a1-7fa2-b4a2-6097202c109e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-14ae-7743-a741-94ef86835665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-16da-73a2-9a73-5d86326ed799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-2df1-7180-b145-79bb0a7a9173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-311d-7751-ac45-63641c46c6da\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-3455-7582-ba47-449e5044eaa9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-3795-7302-aa78-5d0f841d16ec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:11<00:00, 11.22s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-3ad9-7dc2-aed9-ad7c7ce77d48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7206.71it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-4375-7890-bde4-ffe3782ce047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-4764-7740-bb22-010aa867a6e0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-4c2c-7dd3-99f1-3796cacf15b9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-5564-7872-abc1-ec2af1ca24c6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-58ea-7da2-830c-6b18be43a384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-5c4b-7f42-ae1b-39b64663e28d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:08<00:00,  8.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-5f65-7630-896e-b4a3e803fa69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 1486.29it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-6849-70e2-91ce-4cefa7fd09d2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-6a4f-7223-83d4-635e71cdabca\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-6c5f-7233-a74a-583a60aee083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-744a-7ea0-a1e0-803313f34b59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-7a01-7310-a978-9007ae29fe1c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-7d60-77c0-a35b-ed4158e074da\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-80e5-7ae2-958c-2b79fd9854fa\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:08<00:00,  8.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-8447-72d2-a38e-ecc4ed838696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 6765.01it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-8d03-72c0-b958-70accc758c02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-8ed8-7652-bdb4-5b5d4f8423ee\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-94fc-7361-8b60-be8abf2f080f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-9f1e-7d93-9788-68b273edf589\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-a25c-7583-b978-d36df2fc7100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:06<00:00,  6.92s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-a50a-7f90-a93a-284741332db5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 735.07it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-acf2-7bb2-aa5f-dbd03f6554b6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-af0c-7363-abce-0c7e3615cd5f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-b0e5-7341-bd0d-633a884445de\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-bddf-74e2-8b02-cd91fd320ebd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-c0d9-78f3-bd51-664a433d5ec1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-c3b7-7962-a445-99ed76417734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-c6e8-7ca2-9e26-88f377628bf0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-cc53-7ff0-96c2-06d74921de14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-cf20-7221-ae60-16162afd26be\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:10<00:00, 10.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-d24f-7782-b0c2-65a6782aa277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 751.67it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-da91-7272-ae99-40d7afb537bb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-dcad-7870-a773-6aee40fd4834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-e047-7c02-bb0c-44f1c2b7c6ae\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-e69d-7a40-a2a6-08bc2fbbf167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:04<00:00,  4.53s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-e951-7b51-bf98-d93961db417e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 8630.26it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-f15c-7d20-9e29-5ac4faf37fdb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-f52e-77e0-afb7-824e47f561a3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ec-f77e-7783-8663-4e48af3f8412\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ed-0069-7af0-87b7-adc90dfa6706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ed-0378-7ea2-bac2-aaf983189856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:06<00:00,  6.34s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ed-06d8-7830-9dca-bd70a4c94cbd\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Why did Stephen Hawking argue for space colonization as a means of saving humanity?\n",
            "Stephen Hawking argued for space colonization as a means of ensuring the survival of humanity.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How does the mass launcher use the principle of the linear induction motor to launch lunar material?\n",
            "The mass launcher uses a linear electric motor, not the linear induction motor. According to the text, the linear electric motor accelerates the bucket and its loaded payload to lunar escape velocity of 2400 m/s over a distance of 10 km at an acceleration of 30 g.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the advantages of locating the colony in large orbits around L4 and L5?\n",
            "1. Sixty percent of the nearside surface of the Moon is covered with vast, dark basaltic plains, or \"marias.\" These plains are thought to be solid and have in many areas little relief. They appear to be free of boulders and rocks, or have rocks of small size. The surface density of these plains is less than average and would make them a good source of the low density material needed for the habitat. And, they contain fine grained olivine, basaltic dust, or water bearing material.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are alternative biochemistries and how do they relate to the search for extraterrestrial life?\n",
            "Alternative biochemistries refer to the possibility that life on other planets or moons might be based on different chemical building blocks and processes than those that exist on Earth. While the discovery of water, carbon, hydrogen, oxygen, and nitrogen, the four fundamental elements for life as we know it, is considered crucial for life to exist, alternative biochemistries could potentially support life with different elemental compositions or chemical reactions.\n",
            "\n",
            "The search for extraterrestrial life is ongoing and, as alternative biochemistries are considered, scientists broaden their understanding of what might be considered as habitable environments. This includes the possibility of life based on other reactants or products, such as:\n",
            "\n",
            "1. Silicon-based life: Silicon could potentially replace carbon as the base of life, much like silicon's use in computer chips.\n",
            "2. Hydrocarbon-based life: Hydrocarbons, compounds consisting of hydrogen and carbon, could be the basis for life elsewhere in the universe.\n",
            "3. Glass-based life: Some scientists suggest that glass-like structures could provide the foundation for life, replacing proteins and other organic molecules.\n",
            "4. Liquid-methane life: On certain planets or moons, liquid methane could serve as the solvent for life processes, replacing water.\n",
            "\n",
            "However, alternative biochemistries add complexity to the search for life, making it challenging for researchers to define and identify what constellations of life might look like elsewhere.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the significance of water availability in determining habitability?\n",
            "Water availability is a crucial factor in determining habitability as it is necessary for life as we know it and serves as a solvent for biological processes. It also has implications for the emergence of life, with comets and other sources depositing water onto early Earth.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the significance of the list of extrasolar planet candidates released by the Kepler Space Observatory Mission team?\n",
            "The list of extrasolar planet candidates released by the Kepler Space Observatory Mission team contains a collection of exoplanets that are considered potentially habit able, indicating that they could have conditions suitable for life to exist on their surfaces or moons.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are some arguments against using space colonization as a solution to human overpopulation?\n",
            "Some arguments against using space colonization as a solution to human overpopulation include: \n",
            "\n",
            "1. Physical impracticality of shipping vast numbers of people into space.\n",
            "2. Overpopulation might be a temporary issue, as population growth rates have slowed down since the 1980s.\n",
            "3. The costs of commercial activity in space are too high to be profitable.\n",
            "4. It might enhance the interests of the already powerful, including major economic and military institutions.\n",
            "5. Shipping people into space would not necessarily solve the problem of overpopulation on Earth, as it would only be moving the problem instead of solving it.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are some arguments for and against space settlement?\n",
            "Two common arguments in favor of space settlement are:\n",
            "\n",
            "1. Survival of human civilization and life on Earth in the event of a planetary-scale disaster (natural or human-made).\n",
            "2. Availability of additional resources in space that could enable expansion of human society.\n",
            "\n",
            "Two common objections to space settlement are:\n",
            "\n",
            "1. Concerns about commodification of space and potential exploitation.\n",
            "2. Fears of militarization of space.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the role of electrical supply and distribution in a space colony?\n",
            "The text does not explicitly mention the details of electrical supply and distribution in a space colony, but based on its context and surrounding information, it can be assumed that a space colony's life support systems include a reliable power source and a method for distributing electricity throughout the colony.\n",
            "\n",
            "Given the information that satellite solar power stations are an essential component of the space colony's design, it can be inferred that the primary source of power in the colony is solar energy.\n",
            "\n",
            "Therefore, the role of electrical supply and distribution in a space colony would be to harness and distribute the solar power generated by satellite solar power stations to meet the colony's energy needs.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the proposed trajectory for mankind's expansion into space colonization?\n",
            "There are various proposed trajectories for mankind's expansion into space colonization, but some mentioned include:\n",
            "\n",
            "1. **Expanding with fewer negative consequences**: Establishing space colonies to reduce environmental devastation and mitigation of overpopulation on Earth.\n",
            "2. **Alleviating overpopulation and resource demand**: Opening up space resources for use, providing life-supporting habitats, and satisfying Earth's resource requirements, reducing demand on terrestrial resources.\n",
            "3. **Enabling a large and sustainable population**: Colonizing space to create a vast population that can live for billions of years, generating immense utility and happiness.\n",
            "4. **Commercial opportunities**: Expanding into space for economic gains through space commercialization, such as solar-power satellites, asteroid mining, and space manufacturing.\n",
            "\n",
            "These trajectories suggest a decentralized and expansive approach to colonizing the Solar System, with a focus on sustainable growth, mitigating environmental impact, and harnessing the resources of space.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the purpose of a heavy lift launch vehicle in space colonization?\n",
            "Unfortunately, the text does not mention the specific purpose of a \"heavy lift launch vehicle\" in space colonization. However, we can infer that it is needed for transporting large objects to space, such as rocket bodies, because it is stated that one of the proposed uses of L5 colonies is as \"foundries of space, manufacturing not only satellite power stations but also radio telescope antennas many kilometers dimension, optical telescopes of very large size, and vessels intended for scientific voyages to points farther out in space.\"\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the advantages and disadvantages of the Bernal sphere as a habitat configuration?\n",
            "The Bernal sphere is a spherical habitat configuration with agriculture placed in thin toruses outside the shielded sphere. \n",
            "\n",
            "Advantages:\n",
            "\n",
            "1. Efficient in shielding requirements, needing 300,000 t less than the banded torus.\n",
            "2. Thousands of tons less than other configurations in shielding mass.\n",
            "\n",
            "Disadvantages:\n",
            "\n",
            "1. Requires 3-4 times as much atmospheric mass as other possible forms.\n",
            "2. Requires 2-4 times as much structural mass as other possible forms.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What factors affect the economic viability of space colonization for the production of SSPS's?\n",
            "Cost uncertainties, market uncertainties (acceptance of new technology), and need for additional infrastructure such as second-generation shuttle system affect the economic viability of space colonization for the production of SSPS's.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What factors were considered in determining the size and distribution of the population in the space colony design?\n",
            "The area allocated per person was a key consideration in determining the size and distribution of the population in the space colony design.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are some proposed models of transplanetary or extraterrestrial governance in the context of space colonization?\n",
            "  1. **International Treaties:** The Outer Space Treaty (1967) is the main international treaty governing space activity. It asserts that outer space is a common heritage of all humanity and prohibits national appropriation by claim of sovereignty.\n",
            "  2. **Common Heritage of Mankind:** This concept asserts that space resources should be managed globally, with all nations sharing the benefits of space exploration and use.\n",
            "  3. **International Space Agency:** A proposed model of collaborative, global management, where multiple nations and organizations work together to govern space activities and share resources.\n",
            "  4. **Global Governance:** A framework in which international laws and regulations are enforced by a designated authority, ensuring a unified approach to space governance.\n",
            "  5. **Self-Regulation:** A decentralized approach where organizations and individuals are responsible for self-governing their own space activities, with minimal external regulation.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What role did NASA play in determining the habitability of KOI-1686.01?\n",
            "NASA proved KOI-1686.01 to be a false positive.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the effects of isolation in closed environments on the mental and emotional health of colonists in space colonization?\n",
            "The effects of isolation in closed environments on the mental and emotional health of colonists in space colonization include depression, sleep disorders, and diminished personal interactions. The confined spaces of space life and the monotony and boredom of long space travel contribute to these issues.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the characteristics of TOI-700_d?\n",
            "TOI-700_d is a potentially habitable exoplanet with these characteristics:\n",
            "- Type: M2V star\n",
            "- Mass: ~1.72\n",
            "- Radius: \n",
            "- Surface temperature: \n",
            "- Semi-major axis: 0.87 au\n",
            "- Orbital period: 37.4 days\n",
            "- Transit depth: 101%\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How is a solar furnace used in the production of aluminum from lunar soil?\n",
            "The text does not directly explain how a solar furnace is used specifically in the production of aluminum from lunar soil.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 1454.84it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ed-6cfa-7201-8795-f806f950fea1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ed-6fb2-7473-a40c-65f847e1bc9f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ed-73ec-7661-84fc-02b664754645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ed-828e-73b1-a2f5-b9cfaec5d280\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ed-857d-7611-81b2-845057dc1a16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ed-889f-7283-9c48-935684708fd7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ed-8bdd-7bd1-8b11-dfd1f2e0f4d9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:09<00:00,  9.57s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ed-8f2e-7742-839e-29df1aafb49a\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m6\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m7\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m8\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m9\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m10\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m11\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m12\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m13\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m14\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m15\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m16\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m17\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m18\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m19\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m20\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": false}\n",
            "{\"relevant\": false}\n",
            "{\"accurate\": false}\n",
            "{\"concise\": false}\n",
            "{\"relevant\": false}\n",
            "{\"accurate\": false}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": false}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": false}\n",
            " {\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": false}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": false}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": false}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": false}\n",
            "{\"relevant\": false}\n",
            "{\"accurate\": false}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": false}\n",
            "{\"accurate\": false}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the psychological challenges faced by astronauts during prolonged space missions?\n",
            "This section of the text does not specifically discuss the psychological challenges of astronauts during prolonged space missions. It focuses on the need for certain living conditions, the concept of weightlessness, and its effects on human physiology.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 965.54it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ee-7994-7e23-b0cb-13fce003ed12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ee-7b72-7530-84c8-ff2e184940b6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ee-8948-7cf0-a73c-917e65b428cc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ee-8cf7-7f21-9fb7-502376874273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:06<00:00,  6.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ee-9052-7383-b667-02850c25068f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7681.88it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ee-98c3-7ae1-96b9-5d60f28cbb1b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ee-9ac6-71b2-b0fa-92fd0ce292f4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ee-9f4a-7b81-8815-77e8fd1ea4a2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ee-ab05-7340-a78d-928a0a94f23d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ee-b03f-73b2-a5ad-066500c388dd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ee-b60e-7581-bed0-5234567651ed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ee-bbe4-7123-b1ab-8e21e5698395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ee-bef7-7883-8e5e-8f5927bb7577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:11<00:00, 11.44s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ee-c244-7873-90b8-0a1886eba15d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 3685.68it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ee-ca7a-7703-833b-f1e5cf68d904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ee-cc92-7d50-acf3-fa3f1bedd725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ee-cf0f-7d51-a9ba-11d561a7a50e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ee-e209-7120-b6df-6d89454cc9d0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ee-e630-7191-8a52-3eb638342e91\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ee-e937-7e03-9724-afc9661967c5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ee-ece6-7ec1-b3c5-f45669003dc0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:10<00:00, 10.58s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ee-f0c2-7710-9c9f-7aae023c1952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 1387.01it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ee-f914-7780-9bf5-505fe14a5d64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ee-fb5b-7af2-88b0-fce46dbe78e2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ee-fdbe-74e2-a590-11683183184a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-1c9e-7fa3-b0d1-b0096563493e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-1fc6-7433-9265-c188acbfcdaa\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-23b4-7ca2-b15d-3e8624b38585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-26a6-7121-890c-eb4d9a68c428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-29b0-7ef3-9d71-0fff576b8d8f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-2cea-7ad1-bf5d-33a2983dde86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-2ffa-7902-a33e-a8f5d4c60b07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:15<00:00, 15.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-33a5-7a50-8cf1-beb348b96d7d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 353.56it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-3bb4-75c1-8bb5-4ed2f29db0c2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-3dea-7643-bf7f-1aacd14c24aa\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-403f-7fd0-9f44-cac900949ca5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-4a90-7292-8aa7-de71dd8f3403\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:05<00:00,  5.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-4d6f-7061-af71-6b7680adae9b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7598.38it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-5783-7eb1-8409-eae4b2d176f0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-599c-7bc2-80b8-f5d9d0fe4301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-5f31-78c2-9a9e-3fd74afe633b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-6854-76b1-8540-cb99942dcfce\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-6bf0-7c31-ae4b-d5f23f99cf2a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-709b-7ba2-8706-b6206e1ec511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:08<00:00,  8.79s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-73c6-71c1-9bb9-b8c88cbf3da3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 783.84it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-7efc-7ed0-b1d4-8fd208cf68c6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-810a-7701-95f7-e50c3ce3d29a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-831d-7353-8b95-ab7cdbf6bab5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-9289-7282-a4b5-16e17f4bb953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-95ca-7db2-ac35-8bb91dd9f8f8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-9b2c-73e3-ab40-528026593e40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-9e1c-7c21-bacb-f3519f8fcaf4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:09<00:00,  9.61s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-a153-7ac0-8ac1-d8ea7f57147a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 832.04it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-a9a4-7462-b27f-e27c5de329e6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-abe6-7020-8c0c-657e9804b681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-ade2-74c0-a95d-6bcce951c317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-b6e0-7153-8067-8d8b1ad3e73a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-b9d8-7802-ab33-c40d9bbe3276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-bd0d-72f3-b5b3-989a0b16fb4e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:06<00:00,  6.64s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-c049-73d2-9f38-fa5cf5af3f57\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7013.89it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-c8c0-7221-af68-33f0f8a6fc63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-cb43-72a3-9b68-7315adc73daf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-d010-7210-bcaf-27aecf612a0a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-e0c2-7c83-bbe9-8a3edd12647f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-e39f-7d42-97dd-383eb118ffc1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-e69a-7c31-891d-e9cba3712029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-e979-7191-a36e-4741a14beae4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:10<00:00, 10.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-ec91-70d0-a4df-2135d52a1974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 567.41it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-f4d4-7560-b436-13c63ea4934b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-f8a3-77c2-ae6c-2cf0f77aed6a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ef-fbc3-7470-8be1-f61c33f30c8c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-120c-7360-8b3c-4045e95cb369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-14f0-72e1-880d-a242ed54dc7d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-17ef-7fb3-9735-aa0813a78f56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:10<00:00, 10.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-1b07-7ce2-9d8c-9d2a2804ac69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 5023.12it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-235a-7df2-bd7c-1826dad59281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-257d-7763-acf0-babd587a6207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-275c-7cc0-b9ef-41baaca6b59f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-3654-70a3-8d27-f062aa15f77a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-3979-7280-833d-0b23cd6e6697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:07<00:00,  7.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-3c9b-7d40-89b0-b8b144934a2e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 6482.70it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-448e-7740-998b-08fb34152fea\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-468c-7ff1-bf13-25d22137e72e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-492e-7d21-bcce-4cd200ec4e8d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-57dc-7f33-bf03-79bad31ba4e5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-5afe-7121-b917-67153eddde7a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-5e17-7113-9b5f-25bd05699da6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-612c-7a40-82a2-fb11a4dd20b2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-6442-7860-ac15-eb87de579b28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-6787-72e0-8d14-601c83de941c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:10<00:00, 10.69s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-6ae7-7d92-966a-88ef58a1d033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 333.84it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-7375-7153-ad68-14d9ba4f1561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-75ec-76e3-b1a3-79fadb682cf9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-780e-7803-b616-7f8acd5ae539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-7f13-7bd3-8f86-62e641c17eba\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-823d-7bd0-a398-7fc73fd386bf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:05<00:00,  5.58s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-8588-7422-aac9-4b5e938c3f80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 572.37it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-8e63-7573-9dfc-49e56350a019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-9011-7c60-9ceb-e8177157ed71\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-91ea-70e0-ad31-3a00f502bdc1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-95ab-7b22-91d5-7cda5cd4da82\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-98b2-7062-947c-485d34180647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:04<00:00,  4.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-9b8d-7450-b803-ef87d573ff2d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 881.34it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-a3b3-7922-ba8d-43bba3131bf0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-a69c-7a32-aebc-f042b3330362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-a894-79c3-ab86-08e38320a57e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-beba-7772-8a8f-ad5c55333615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-c208-7393-b5d2-87c83bf1b9ca\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-c558-72f0-a239-d7d7e81c2eaa\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-c88f-7401-80e0-d331ed20cfe4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-d5cd-71f1-bbfc-c7b27b0eae9d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-d91b-7ed3-b161-a86704422aa7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-dc76-74c0-b022-c5ccc72e3ed4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-df8a-7b73-8186-ecf0dd1935a0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-e25a-7551-b46f-de272ca8a0aa\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-e628-7590-a538-d3fa6d558bb2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:18<00:00, 18.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-e988-73e2-b456-6da7452b7f05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 8144.28it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-f1cf-7e41-8d9c-e223852183d9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-f371-7201-8e9a-f59d5925dfaa\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-f596-7023-b00b-7fd795a94cb9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:03<00:00,  3.95s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f0-f9f1-7372-9f67-9526328d633a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 5729.92it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f1-067c-7400-95b2-e1228d33b86d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f1-08a9-7900-a97b-0a294b27b10b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f1-0b14-7313-bcc9-f21265d6312e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f1-16c3-7881-8e51-d991695c6e5a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:05<00:00,  5.68s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f1-199e-7be3-93d5-f1c19375629f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 766.36it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f1-21e9-73b0-8c1e-f99ab9251b64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f1-23df-74e3-89c9-3309d994b343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f1-27c2-7740-837f-c42e1d3151a2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f1-3166-78e3-9ead-5f06ada33cf6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f1-34d2-79b3-ad7b-b4669a60dede\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f1-3828-7ae1-9072-e9a1a9146a0c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f1-3b56-75b0-b570-450fd6a7e33d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f1-3e5d-78a2-a716-b879469984d4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f1-41b0-7e90-89f3-05f81df49d70\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:09<00:00,  9.83s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f1-44cf-7000-830c-9eb6f1bb8bcf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7037.42it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f1-4d9d-70e2-ba1f-5af5f1acfc79\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f1-4f8b-7962-8d4e-fb9d52e61ea4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f1-514f-7562-8b4e-0945886de29f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:02<00:00,  2.99s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f1-55bf-7000-b956-24874561308b\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m21\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"concise\": false}\n",
            "{\"relevant\": false}\n",
            "{\"accurate\":false}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How does volcanic activity affect the colonization potential of the Saturnian moons?\n",
            "Volcanic activity does not significantly affect the colonization potential of the Saturnian moons, as stated in the text. In fact, tidal forces caused by Saturn and the potential presence of water ice in various moons, as well as the discovery of water-bearing moons like Enceladus and other Jupiter trojans, provide a suitable environment for possible colonization.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What factors limit the habitability of exoplanets around red dwarf stars?\n",
            "Red dwarf stars make up between 70 and 90% of all the stars in the galaxy. They are small, with masses ranging from 0.08 to 0.45 solar masses and emit very little light, requiring planets to orbit very close to their stars for Earth-like temperatures. This causes tidal locking, where one side of the planet always faces the star, and the other side faces away. Other limiting factors include:\n",
            "\n",
            "1. Gravity of the star, which could squeeze atmosphere away from the exoplanet\n",
            "2. Flares from red dwarf stars, which could strip away the exoplanet's atmosphere\n",
            "3. The need for a thick atmosphere to transfer heat, which could block sunlight and photosynthesis.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the significance of solar power satellites in the design for space colonization?\n",
            "Solar power satellites (SPSs) are anticipated to be a major export of the initial space settlement designs and play a crucial role in space colonization. They will use wireless power transmission to send power to locations on Earth or to colonies on the Moon or in space. This method is extremely beneficial, with zero emissions and a smaller ground area required per watt compared to conventional solar panels.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the chosen method for refining aluminum from lunar anorthosite?\n",
            "Melt-quench-leach production of alumina followed by high temperature electro-winning of aluminum from aluminum chloride.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How does the expense of providing human workers encourage reliance on automation and push for extreme reliability and maintainability in space commercial ventures?\n",
            "The expense of providing human workers in space encourages reliance on automation because of the high cost of human life support in space, as mentioned in the context: \"A space economy equivalent to a considerable industrialized area would be necessary to bring costs of life support and human transport into the same order of magnitude as costs of production, leaving only the administration of salvage operations and reclamation of non-productive categories for human workers.\" This high cost likely motivates the development of automation to replace human workers and minimize these costs.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the suggested advantageous locations for colonization according to Robert Zubrin?\n",
            "Saturn, Uranus, and Neptune.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the chief assumptions about habitable planets in terms of their characteristics?\n",
            "Habitable planets, in terms of their characteristics, are assumed to be rocky and have a water environment with suitable chemical composition for Earth-like life to exist.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How has space colonization been discussed as a continuation of imperialism and colonialism?\n",
            "Space colonization has been discussed as a continuation of imperialism and colonialism due to concerns that it may perpetuate the same patterns of exploitation, oppression, and marginalization seen on Earth, particularly through the use of language and narratives that echo the \"manifest destiny\" and \"New Frontier\" ideologies.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are some criticisms of space colonization?\n",
            "Some criticisms of space colonization include: \n",
            "\n",
            "1. It's an expensive and costly venture with no known return on investment for a long time. \n",
            "2. It cannot alleviate the problem of human overpopulation, as proposed by some, as Earth's population growth rate has slowed down. \n",
            "3. The costs of commercial activity in space are high, making it difficult for it to be profitable compared to Earth-based industries. \n",
            "4. It may favor the interests of powerful institutions rather than benefiting humanity.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m22\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m23\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m24\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m25\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m26\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m27\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m28\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m29\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m30\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m31\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m32\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m33\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m34\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m35\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m36\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m37\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m38\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">38</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m39\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">39</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m40\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 1500.65it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f1-9100-7783-9c0d-256b1fc18342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f1-936e-7ac3-ac3e-b45531c688d4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f1-95e4-7bd3-a6d8-c6eedc4cd205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f1-9e46-78f0-b4cc-6b538503b3a6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f1-a1c7-7103-91a8-419352ce0b51\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f1-a4b8-7c12-8290-7a117d09058a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:07<00:00,  7.80s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f1-aad9-7cc2-ac2b-76474316c075\n",
            "{\"concise\": false}\n",
            "{\"relevant\": false}\n",
            "{\"accurate\": false}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\":true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": false}\n",
            "{\"relevant\": false}\n",
            "{\"accurate\": false}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 6574.14it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f1-f363-72c0-959c-17a426f2f442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f1-f662-7e92-9054-2e80b233c409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f1-f895-7c21-af7c-6dde0c8ee352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-042d-7ad3-811c-faa1db3bc64f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-07d3-72b2-8d8a-b60129b86db7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-0b25-7df0-82ab-251984660b5f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:07<00:00,  7.70s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-0e6b-7cc2-8d54-72e085257abe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 769.60it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-1696-7f83-9367-0206afbd7188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-195d-77f1-9e3e-7b4539b6764f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-1bcc-7b41-af50-49b781f74c36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-3528-7b43-b74a-d7996de29493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-38d0-7ec2-9b18-a5047b1f0142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-3bc7-7251-94b1-707f74727884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-3eaa-7ea0-af9f-1b7de8ee91c4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-4184-70d1-9892-b1cbc62d50c2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-4556-7e23-a560-120847b3a40d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:13<00:00, 13.91s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-49f6-71d3-9dea-24d55acad044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 779.32it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-5226-7972-9ae1-e13e8a41a2a3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-54ea-7332-8078-f7d91c753775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-5704-7521-ba0e-0160a7e1495c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-63fa-7de1-b207-8dc4327c4d1b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-66d3-7040-b750-c28d30c4b891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-69d4-7831-9997-64de33abc743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-6cf0-73a1-b037-94dcd1f7c04d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:08<00:00,  8.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-6ffb-7840-9a9b-707478f93f7c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 1520.78it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-7802-71c2-807f-bb7c6f8728c3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-7a12-79b1-b5bb-a35aabcded43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-7c3b-7c93-8f0a-26ca0228e8a7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-8119-72b2-9c14-e4bb4e74c28b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-84f3-7270-9890-a091fd9efd6f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-90e6-7563-b9f1-e04a815e8cee\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-93b6-7683-8b3d-8f5f907d33ad\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:08<00:00,  8.65s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-96c6-7202-9d29-ec0aa3595123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 711.99it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-9ebe-75d2-bbd1-789396555e0f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-a0f2-7e41-b720-0acb7b98b7a2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-a2f4-75a1-a0b5-2e54de853850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-b104-7573-b628-01f681d8d4f5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-b3c6-7cd0-8d5d-b7f67a8f784a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-b775-7040-8111-42d09d16539f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-bae1-7000-856b-9f4a0f305094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:08<00:00,  8.76s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-bda8-7ac3-84c6-d7bc3aabf1a4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7121.06it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-c62c-7dc0-af15-73c7e3055f75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-c7f5-7f51-8f73-ec0e3fc84ecb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-c9dc-7b60-a286-b75e8219b7cf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-cc45-7883-96eb-58e734526954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-cf21-79c3-85ed-723a74108f1e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:03<00:00,  3.92s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-d252-7e13-9e38-0f690b5cdf6b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 344.67it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-daac-7bb1-bf16-dfb5dbd5efe9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-dce6-77c1-8838-3eae9f5282f2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-dee5-7450-aff0-bd632af40697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-e451-7de0-ade7-78383e31ea43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-e7f4-75e0-84c5-43b5f3c15f21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-eb55-7612-9376-02e47df79c65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:05<00:00,  5.91s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-ee7e-7e21-a1ef-9ba66d7be4cf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 725.28it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-f6ed-7ac1-94f2-3747943adde2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-f8d4-71c3-95f1-6a07faeeab10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f2-fad6-72b3-ae21-df4e835caddf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f3-046d-7963-834d-861450171424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f3-07ac-71e1-b4a4-2a0821d6b39d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:05<00:00,  5.81s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f3-0aab-7a11-8964-c8954c7c8698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7025.63it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f3-12bd-74b0-a7b4-16692af33ba8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f3-15ff-7f20-9520-4d5cb4d3826e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f3-1845-73e1-a251-9f706f9ad0ca\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f3-2566-7a20-a1ba-dbd017984769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f3-286c-7053-bed6-80571fa58987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f3-2b55-7313-b3e5-acd39f08724a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:07<00:00,  7.84s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f3-2e53-76d0-aa27-c0dc2fcb964d\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m41\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m42\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m43\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m44\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">44</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m45\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">45</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m46\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m47\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m48\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m49\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m50\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation summary\n",
              "\u001b[1m{\u001b[0m\n",
              "    \u001b[32m'llm_judge_scorer'\u001b[0m: \u001b[1m{\u001b[0m\n",
              "        \u001b[32m'concise'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m35\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.7142857142857143\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'relevant'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m40\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.8163265306122449\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'accurate'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m36\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.7346938775510204\u001b[0m\u001b[1m}\u001b[0m\n",
              "    \u001b[1m}\u001b[0m,\n",
              "    \u001b[32m'tonic_validate_score'\u001b[0m: \u001b[1m{\u001b[0m\n",
              "        \u001b[32m'answer_consistency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.7995578231292517\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'duplication_metric'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.12244897959183673\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'answer_similarity'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m3.4285714285714284\u001b[0m\u001b[1m}\u001b[0m\n",
              "    \u001b[1m}\u001b[0m,\n",
              "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m76.03223681936458\u001b[0m\u001b[1m}\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
              "<span style=\"font-weight: bold\">{</span>\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'llm_judge_scorer'</span>: <span style=\"font-weight: bold\">{</span>\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'concise'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7142857142857143</span><span style=\"font-weight: bold\">}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'relevant'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8163265306122449</span><span style=\"font-weight: bold\">}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'accurate'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7346938775510204</span><span style=\"font-weight: bold\">}</span>\n",
              "    <span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'tonic_validate_score'</span>: <span style=\"font-weight: bold\">{</span>\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'answer_consistency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7995578231292517</span><span style=\"font-weight: bold\">}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'duplication_metric'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.12244897959183673</span><span style=\"font-weight: bold\">}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'answer_similarity'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.4285714285714284</span><span style=\"font-weight: bold\">}</span>\n",
              "    <span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">76.03223681936458</span><span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8e8-0221-7812-80d1-d53ac8e57e56\n",
            "RAG Model: Snowflake/snowflake-arctic-instruct\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How is the sense of spaciousness addressed in the design of habitats for the colony?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the steps involved in the process of producing aluminum from lunar soil, specifically in regards to glass grinding and acid leaching?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the importance of atmospheric pressure in large colonies in space?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How does the expense of providing human workers encourage reliance on automation and the push for extreme reliability and maintainability in space commercial ventures?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are some potential benefits of long-term development in space?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the gravities of Jupiter's Galilean moons and Saturn's Titan compared to Earth's Moon?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What needs to be better understood before evaluating the usefulness of other libration points for space colonies?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the likelihood of gaseous sub-Neptunes being habitable?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How can a metabolism exist outside the classical habitable zone?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Why do some scientists and experts argue for the colonization of space as a means of saving humanity?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are some criticisms of space colonization?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the purpose of positioning another spacecraft fueled for a return to Earth in orbit around Mars?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the relationship between propulsive effort and travel time in space travel?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the advantages of the Moon for the space colonization program?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How could self-replication enable exponential growth in space colonization?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What factors determine the habitability of planets within galactic habitable zones?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the difficulties associated with automated rendezvous and interception in the context of the transport system for a lunar colony?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How does the design of the space colonization system incorporate existing technology?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the chosen location for the first space colony?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What role does critical path analysis play in determining the sequencing of mirror, power plant, shield, and internal construction in the fabrication of space habitats?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the disadvantages of the intense ionizing radiation on the moons of Jupiter for colonization?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Why did Stephen Hawking argue for space colonization as a means of saving humanity?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How does the mass launcher use the principle of the linear induction motor to launch lunar material?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the advantages of locating the colony in large orbits around L4 and L5?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are alternative biochemistries and how do they relate to the search for extraterrestrial life?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the significance of water availability in determining habitability?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the significance of the list of extrasolar planet candidates released by the Kepler Space Observatory Mission team?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are some arguments against using space colonization as a solution to human overpopulation?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are some arguments for and against space settlement?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the role of electrical supply and distribution in a space colony?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the proposed trajectory for mankind's expansion into space colonization?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the purpose of a heavy lift launch vehicle in space colonization?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the advantages and disadvantages of the Bernal sphere as a habitat configuration?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What factors affect the economic viability of space colonization for the production of SSPS's?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What factors were considered in determining the size and distribution of the population in the space colony design?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are some proposed models of transplanetary or extraterrestrial governance in the context of space colonization?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What role did NASA play in determining the habitability of KOI-1686.01?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the effects of isolation in closed environments on the mental and emotional health of colonists in space colonization?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the characteristics of TOI-700_d?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m6\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m7\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m8\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m9\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m10\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m11\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m12\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m13\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m14\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m15\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m16\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m17\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m18\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m19\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How is a solar furnace used in the production of aluminum from lunar soil?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m20\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the psychological challenges faced by astronauts during prolonged space missions?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How does volcanic activity affect the colonization potential of the Saturnian moons?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What factors limit the habitability of exoplanets around red dwarf stars?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the significance of solar power satellites in the design for space colonization?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the chosen method for refining aluminum from lunar anorthosite?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How does the expense of providing human workers encourage reliance on automation and push for extreme reliability and maintainability in space commercial ventures?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the suggested advantageous locations for colonization according to Robert Zubrin?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the chief assumptions about habitable planets in terms of their characteristics?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How has space colonization been discussed as a continuation of imperialism and colonialism?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:together:error_code=model_not_available error_message='Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.' error_param=None error_type=invalid_request_error message='Together API error received' stream_error=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are some criticisms of space colonization?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_output failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 205, in predict_and_score\n",
            "    model_output, model_call = await async_call_op(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 57, in async_call_op\n",
            "    call_res = func.call(*args, __should_raise=True, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 385, in call\n",
            "    return _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-25-66d9653e4bc1>\", line 28, in predict\n",
            "    answer = predict(self.model, prompt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-24-5407db8d84e6>\", line 4, in predict\n",
            "    completion = client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/resources/chat/completions.py\", line 141, in create\n",
            "    response, _, _ = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 249, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 632, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/together/abstract/api_requestor.py\", line 701, in _interpret_response_line\n",
            "    raise self.handle_error_response(resp, rcode, stream_error=stream)\n",
            "together.error.InvalidRequestError: Error code: 400 - {\"message\": \"Unable to access non-serverless model Snowflake/snowflake-arctic-instruct. Please visit https://api.together.ai/models/Snowflake/snowflake-arctic-instruct to create and start a new dedicated endpoint for the model.\", \"type_\": \"invalid_request_error\", \"code\": \"model_not_available\"}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m21\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m22\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m23\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m24\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m25\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m26\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m27\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m28\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m29\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m30\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m31\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m32\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m33\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m34\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m35\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m36\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m37\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m38\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">38</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m39\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">39</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predict and score failed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predict and score failed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 454, in eval_example\n",
            "    eval_row = await self.predict_and_score(model, example)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 615, in wrapper\n",
            "    res, _ = await _do_call_async(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 494, in _do_call_async\n",
            "    res, call = await execute_result\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 341, in _call_async\n",
            "    return handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 339, in _call_async\n",
            "    res = await func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/flow/eval.py\", line 379, in predict_and_score\n",
            "    result = await async_call(score_fn, **score_args)\n",
            "  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n",
            "    return await loop.run_in_executor(None, func_call)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 623, in wrapper\n",
            "    res, _ = _do_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 441, in _do_call\n",
            "    execute_result = _execute_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 350, in _execute_call\n",
            "    handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/weave/trace/op.py\", line 348, in _execute_call\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"<ipython-input-29-1c91fbb1eb1b>\", line 5, in llm_judge_scorer\n",
            "    answer = model_output['answer']\n",
            "TypeError: 'NoneType' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m40\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m41\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m42\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m43\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m44\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">44</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m45\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">45</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m46\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m47\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m48\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m49\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m50\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation summary\n",
              "\u001b[1m{\u001b[0m\u001b[32m'llm_judge_scorer'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'tonic_validate_score'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
              "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'llm_judge_scorer'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'tonic_validate_score'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f3-344c-71f2-bad2-e2b18db56ec6\n",
            "RAG Model: mistralai/Mixtral-8x22B-Instruct-v0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How is the sense of spaciousness addressed in the design of habitats for the colony?\n",
            " The design of habitats for the colony addresses the sense of spaciousness by allocating at least 40 m^2 of projected area per inhabitant. This area can be increased by constructing levels within a habitat or several stories within a building. Space architects are tasked with organizing this space to minimize the sense of crowding while still providing necessary services. The literature suggests that this area per person is less than in most US cities but more than in some small French villages.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the steps involved in the process of producing aluminum from lunar soil, specifically in regards to glass grinding and acid leaching?\n",
            " The text does not provide specific steps involved in glass grinding and acid leaching for the production of aluminum from lunar soil. However, it does mention that aluminum refining from lunar anorthosite involves melt-quench-leach production of alumina followed by high temperature electro-winning of aluminum from aluminum chloride. The schematic representation of the various methods by which aluminum might be refined is shown in [figure 4-12](https://nss.org/settlement/nasa/75SummerStudy/figure4.12.gif) and alternative paths are discussed in [appendix I](https://nss.org/settlement/nasa/75SummerStudy/4appendI.html).\n",
            "\n",
            "For glass processing, the text suggests that a possible technique in space for large scale production is removing almost all nonsilicate ingredients by leaching with acid. The resulting glass, of almost pure silica (> 95 percent SiO2), has desirable properties of low thermal expansion, high service temperature, good chemical, electrical, and dielectric resistance, and transparency to a wide range of wavelengths in the electromagnetic spectrum. More details on glass-processing requirements and constitutes are given in [appendix J](https://nss.org/settlement/nasa/75SummerStudy/4appendJ.html).\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the importance of atmospheric pressure in large colonies in space?\n",
            " Atmospheric pressure in large colonies in space is important to maintain life processes adequately. The atmosphere should contain a partial pressure of oxygen (pO2) sufficient to provide high enough partial pressure within the alveoli of the lungs for good respiration yet low enough to avert losses in blood cell mass and large changes in the number and distribution of micro-organisms. The presence of an inert gas such as nitrogen in the colony's atmosphere is also desirable to prevent decompression and provide safety during either accidental pressure drops or oxygen dilution. Maintaining a comfortable relative humidity and temperature is also important for human life support in space.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How does the expense of providing human workers encourage reliance on automation and the push for extreme reliability and maintainability in space commercial ventures?\n",
            " The expense of providing human workers in space encourages reliance on automation and the push for extreme reliability and maintainability in space commercial ventures due to the high costs associated with sending humans into space. This includes the costs of providing life support systems, training, and transportation. Automation reduces the need for human workers in space, while extreme reliability and maintainability are necessary to ensure the equipment functions optimally with minimal human intervention, further reducing costs.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are some potential benefits of long-term development in space?\n",
            " Some potential benefits of long-term development in space include progress in automation, reduced costs due to use of lunar resources and cheap solar energy, improved communication and Earth-sensing satellites, space manufacturing of large crystals and new composite materials, and potential return of resources from the lunar surface or deep space to Earth. Additionally, zero-gravity industries could enable fabrication of strong, lightweight materials like titanium and casting of more homogeneous and stronger metal products. Space colonies also offer a potential solution for low-cost energy production and independence, as well as a clean form of energy production with minimal waste heat and pollutants.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the gravities of Jupiter's Galilean moons and Saturn's Titan compared to Earth's Moon?\n",
            " The gravities of Jupiter's Galilean moons and Saturn's Titan compared to Earth's Moon are as follows: Io has 0.18g, Europa 0.13g, Ganymede 0.15g, Callisto 0.13g, and Titan 0.14g, while Earth's Moon has a gravity of 0.17g.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What needs to be better understood before evaluating the usefulness of other libration points for space colonies?\n",
            " The cost of station keeping at those points needs to be better understood before evaluating the usefulness of other libration points for space colonies.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the likelihood of gaseous sub-Neptunes being habitable?\n",
            " According to the text, gaseous planets are less likely to be habitable. The chief assumption about habitable planets is that they are terrestrial, primarily composed of silicate rocks, and have not accreted gaseous outer layers of hydrogen and helium found on gas giants. The possibility that life may evolve in the cloud tops of giant planets has not been ruled out but is considered unlikely. Therefore, the likelihood of orbs with a sub-Neptune size being habitable is suggested to be low.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How can a metabolism exist outside the classical habitable zone?\n",
            " A metabolism can exist outside the classical habitable zone if it doesn't depend on the stellar light and thrives in the interior of the planet where liquid water is available.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Why do some scientists and experts argue for the colonization of space as a means of saving humanity?\n",
            " Some scientists and experts argue for space colonization as it could mitigate impacts of overpopulation and resource depletion on Earth. By utilizing extraterrestrial resources, demand on terrestrial ones would decline. Additionally, space colonization could ensure the survival of our species in the event of a catastrophic event on Earth.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are some criticisms of space colonization?\n",
            " Critics argue that the slowdown in population growth rates since the 1980s has alleviated the risk of overpopulation, making space colonization less necessary. They also claim that the costs of commercial activity in space are too high to be profitable against Earth-based industries, making significant exploitation of space resources unlikely in the foreseeable future. Additionally, there are concerns that forthcoming colonization and commodification of space may enhance the interests of the already powerful institutions.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the purpose of positioning another spacecraft fueled for a return to Earth in orbit around Mars?\n",
            " The purpose of positioning another spacecraft fueled for a return to Earth in orbit around Mars is to enable the initial crew to eventually return to Earth.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the relationship between propulsive effort and travel time in space travel?\n",
            " In space travel, propulsive effort required to get from one point to another is measured by the total change in velocity (Delta-V). While the distances are roughly proportional to the time required to travel between any two points, the propulsive effort does not necessarily increase with travel time or distance. For example, the Delta-V to go from low Earth orbit (LEO) to lunar orbit is only 300 m/s more than to go to geosynchronous orbit (GEO), despite the difference in distance. Therefore, time and effort of transportation are inversely related, and a balance between them is necessary.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the advantages of the Moon for the space colonization program?\n",
            " The Moon has advantages for space colonization due to its proximity to Earth and lower escape velocity. Abundant ice is trapped in permanently shadowed craters near the poles, which could provide support for water needs. Native precious metals, such as gold, silver, and probably platinum, are also concentrated at the lunar poles. However, the Moon's lack of atmosphere provides no protection from space radiation or meteoroids, and its low surface gravity may be a concern for maintaining human health. Despite this, interest in establishing a moonbase has increased in the 21st century as an intermediate to Mars colonization, with proposals such as the Moon Village for research, mining, and trade facilities with permanent habitation.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How could self-replication enable exponential growth in space colonization?\n",
            " Self-replication could enable exponential growth in space colonization as it would allow colonies to become self-sustaining and independent from Earth. This means that new colonies could be created without the need for resources or support from Earth, leading to an exponential increase in the number of colonies.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What factors determine the habitability of planets within galactic habitable zones?\n",
            " Factors that determine the habitability of planets within galactic habitable zones include the host star's spectral class, luminosity, and age, as well as the planet's orbit, atmosphere, and potential chemical interactions. Additionally, geophysical and geodynamical aspects, radiation, and the host star's plasma environment can influence the evolution of planets and life. Liquid water is necessary but not sufficient for life as we know it, as habitability depends on a multitude of environmental parameters.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the difficulties associated with automated rendezvous and interception in the context of the transport system for a lunar colony?\n",
            " The difficulties associated with automated rendezvous and interception in the context of the transport system for a lunar colony include uncertainties in precision of aim, development of sliding seals able to withstand high pressures and move at high velocities while maintaining acceptable leakage rates, and the requirement for interceptor rockets to use chemical propulsion with hydrogen as fuel. These uncertainties make another alternative, such as an electromagnetic mass accelerator, more attractive at this time.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How does the design of the space colonization system incorporate existing technology?\n",
            " The design of the space colonization system incorporates existing technology by utilizing solar energy to generate electricity and power solar furnaces for refining materials from lunar ores. The system also employs an electromagnetic accelerator to deliver processed lunar ore to the colony. Additionally, the habitat is designed with a rotating structure to provide an Earth-like environment on its inner surface.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the chosen location for the first space colony?\n",
            " The chosen location for the first space colony is a rotating habitat in satellite orbit around the Earth at the distance of the Moon.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What role does critical path analysis play in determining the sequencing of mirror, power plant, shield, and internal construction in the fabrication of space habitats?\n",
            " Critical path analysis is used to determine the best sequencing of mirror, power plant, shield, and internal construction in the fabrication of space habitats. It helps identify the most efficient order of operations to complete the basic shell and the first layer of shielding as quickly as possible, so that spin-up can begin, gravity can be simulated, and construction crew and additional colonists can move in to initiate life support functions within the habitat.\n",
            "___________________________\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concordant\": false}\n",
            "{\"relevant\": false}\n",
            "{\"accurate\": false}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": false}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": false}\n",
            "{\"accurate\": false}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\n",
            "\"concise\": false\n",
            "}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\":true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": false}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{ \"accurate\": true }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 6743.25it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f4-f0a9-7dd0-9d3b-2b2ac0ea5f74\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f4-f4f7-7b41-a46e-347553cdabd0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f4-f75f-7fc2-8d12-68f9dbdf421e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-0ac6-7ff0-b58d-fd91fd947788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-0d9d-78a0-8ae8-3100b580f359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-10d0-7e40-8202-a1e0c044539b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:09<00:00,  9.79s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-13d2-7ea2-a967-90ea10cb27e1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 647.57it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-1c0b-7e33-9ad7-9fec8391b1a3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-1e3e-7272-8e03-c0980a587086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-2082-75b0-add8-e79bc48fb90e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-3d5e-75f3-b193-d5716c18f379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-4229-70f2-84e0-32f0b749e73d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-46fb-74a0-8b64-c8094e281fab\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-4a14-7813-a98c-231228c8a720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-4d25-7e22-a94e-04437ff8273b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:14<00:00, 14.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-5047-76e0-9589-3ecfe16ca4a7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7516.67it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-5921-7333-894c-80e6951e3f11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-5bce-7e12-9495-85cb87f4e1fb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-5e7b-76e1-9744-02d894310bfc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-720d-74f2-9a0e-8080c89dd1cf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-750e-7f72-8f44-e7ef27657dad\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-77f8-7212-888c-b1072dca724a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-7b82-7a40-88ba-f92d18bc03fc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:11<00:00, 11.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-7e74-77a0-80bf-c844d023a2f6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 1271.00it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-8945-70b3-a33e-2b77c0c905dc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-8bb7-7340-b2bb-85e43193d0d2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-8f3e-7433-81fc-78830eaeddfe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-9bd4-7fb3-8927-0eecf57ea923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-9eee-7543-9745-0a1489d26246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-a589-71c3-b004-e49ed5eacf65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:08<00:00,  8.90s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-a893-7c02-a986-5964127a4c47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 788.11it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-b0fc-7a71-af45-6ff847d76d24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-b3a5-7970-856b-a340ec242598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-b5cd-74b0-9bf6-6c914be02f21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-c798-7191-8137-fa05876ee67c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-ca49-75f3-b987-9d18bbcd93ee\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-cdfb-70b1-b45f-0b72ed3b56e4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-d0b8-7900-842b-8471cd24548f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-d3c6-7db2-955c-0f641090b57a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-d6d4-7f11-a3bf-5e4e52bdc026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-db9f-7493-8343-6e4a21adc862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-df9d-7331-af14-abcad3cc8219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:13<00:00, 13.66s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-e2a1-79c3-85fb-1fd140b68115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 750.73it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-ebb0-7b21-8439-b3f9ff604ed2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-f120-75a2-8367-9383d7ff1e94\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f5-f453-7b63-8e62-b55888f47417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-01d4-7af3-81fa-724d916fc4f7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-0539-7ea2-bf6b-6a6d68a1c798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-0851-7ac2-94d0-a57e9afc6ba2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-0bc3-7f61-b608-2a1dcdf93676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-0ef7-7bd1-b252-361c729d7a16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:10<00:00, 10.72s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-122e-71e2-a30c-f871cb7fe6f0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 776.29it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-1a97-7dd1-a313-708fe93cfdb4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-1c89-7031-8cb1-b5f8d3630d36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-1eab-7730-943b-c00624d3d934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-23d2-76f2-8d82-e00163ca76ba\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:03<00:00,  3.88s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-26cb-76e1-9975-8e10846c2af9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 1470.65it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-2ee0-7111-b58a-120c8d6a9ea7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-3109-7c91-8b3c-ae51b91c00ee\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-3311-7f50-901f-c6e3505112c9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-3f26-7073-b815-8b9a70333b95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-4295-7550-b048-eb89e7ed4daa\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-4612-7f71-bb01-a918201a3f21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-48ea-7072-a5c0-5562f74079a6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:08<00:00,  8.27s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-4c12-7c40-827e-92301b2b4e88\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 717.10it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-5472-74b2-b2dc-6e7f54e50ab9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-5633-7043-8dc1-96fce3d8f39b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-5846-7e01-94eb-3f22bcede0bb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-5e03-7a83-9db8-9effe7b8c3b0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-6115-7a61-93dd-5b1ad356cfcd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-661d-79f3-810f-4df8d7b124c6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:06<00:00,  6.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-691d-7fd0-a3c6-225eb688dfc5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7013.89it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-718c-78a3-a054-a7333ace01b9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-7393-7551-8852-08e08129035f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-758b-7743-9927-c2f77b60271d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-7e18-7ff1-9e59-aeceb749f401\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-810e-71a0-bda0-5761e8556390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:05<00:00,  5.53s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-83fe-7ed2-94a1-882fa5827da3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 6887.20it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-8c71-7541-be3b-0bb22317bf2d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-8e9d-7bf0-90d7-5b926e47406e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-9094-7e00-bacb-70e9dde001c8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-9d94-7883-8c23-7a4e413aa8e4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-a0d4-7063-8f44-ee1f71acf0eb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:06<00:00,  6.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-a3f7-77e3-bcf2-ecc374470da6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7543.71it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-abe6-7133-8823-890cd942b27b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-ada6-7011-9dd7-6698a4bfc9de\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-b015-7611-b2a8-3a1093438314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:03<00:00,  3.42s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-b617-7103-a5d1-563e46663591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 647.97it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-be6c-7c70-95ea-fc6ffae9855a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-c11e-7af0-a04b-81fe2fc128d1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-c489-7130-9922-fb88dac94a47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-d6ee-7941-a2cf-4d89118a520a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-da3e-7bf0-b365-417a75156a26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-dd42-7580-9b9d-9716a3dd3122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:09<00:00,  9.49s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-e038-77e3-b588-9da63609162d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 768.75it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-e89d-72b3-8c0c-7c9acaea6c6e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-eb2b-7770-97cd-538a092cb547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f6-ed7d-7343-bf57-4840a1904e93\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-01c4-7951-98c3-4d57b8d9ebc2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-05ec-7270-b3e7-37959fe5da64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-0951-70d3-9855-987a1ff4f573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-0d28-7422-9014-a8c09a7e31b2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-1071-72c0-ba47-3d201973255b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-1376-72a2-a7a6-5437cdc22b8f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:12<00:00, 12.57s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-16a4-7641-9e58-bd71dc12c7c0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 799.07it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-1ed0-7040-ba40-9c2f50e9ad75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-2177-7180-9b1f-ef392827cb8f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-236b-7561-b9ec-e1a8312003b4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-2c8c-79c0-acdb-b1fc264629b3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-2f70-7d52-b834-fe67f96b21c9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-34a0-7352-a37b-2a003fb1cef8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-379a-79a0-a825-832395b0b930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-3f7a-7ec2-808e-e2ffb26da689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:10<00:00, 10.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-4266-77c2-9e17-c1b54c7e4fea\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7584.64it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-4b5a-7111-a0dd-808de9f09bc4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-4f88-7980-84c1-f87806148413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-5161-7730-81ef-6868f0f7cc24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-5f6e-78f2-ab56-3cf304540ab9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-6229-7600-957d-a85d1343750f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-660e-71d1-a741-a9197683e734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-692f-7fa0-8b36-6e8500bff958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-6c7b-7572-b61f-741ae9afa161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:10<00:00, 10.73s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-715d-7d61-9408-b105ac60bf77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 1433.95it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-7a27-7a83-adb7-547f0017fca6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-7dfe-75d1-8019-6c98a360827e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-8042-7d53-a08e-83b8595f96b7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-89e8-72c1-95ce-d4abd1933517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-8ccf-7a21-8f65-b36fc436ab29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-914d-7fd0-b7e0-7cdc971bd1f0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:08<00:00,  8.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-96c5-7540-9672-f5a824229425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7410.43it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-9f32-7772-bd7b-c3ff13fa86e5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-a2a9-7753-9be5-22bd7008027a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-a4e0-7f32-943b-67d5a49eacff\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-b05e-7b51-b729-4b9d535d0eec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-b3fd-76d1-bb8a-3ba60a58220c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-b76c-7432-9850-ef8b5c1c1ca9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-ba7b-7e02-b265-a8d7cdf1880e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:08<00:00,  8.50s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-bd79-7e21-81cc-a98d39942cf3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7084.97it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-c5a2-7822-9dc3-eaa7c45c3e6d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-c7ae-71c3-8f8e-f72a85a0237c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-ca21-70f3-a0bc-78a5ee6fe690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-d012-7dd2-b4f2-6350a1f91797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-d6c6-7972-894f-e93e5ce343b0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:06<00:00,  6.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-dc4d-74d0-8342-1e38958bc830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7108.99it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-e466-7750-947a-d6176431afb9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-e708-70c0-9008-7a2676a0c214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-e927-7eb2-810c-c79d81ba1ab2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f7-fdf7-7dd3-aaee-7def0caf20c8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f8-010c-7780-b083-8b639c78381e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f8-0424-7833-b9dd-bc8df41b66a7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f8-0763-7820-b441-bf06c76f1b44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:10<00:00, 10.65s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f8-0a7f-7213-a1fb-435327d9ce0a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the disadvantages of the intense ionizing radiation on the moons of Jupiter for colonization?\n",
            " The intense ionizing radiation on the moons of Jupiter delivers high levels of radiation dosage per day, enough to cause radiation poisoning or even be fatal to unshielded humans within an Earth day. This extreme radiation makes colonization on Io and Europa impractical, with only Callisto and possibly Ganymede being feasible for human colonization due to their lower radiation levels. The radiation also necessitates significant radiation shielding for habitats on Ganymede's low latitudes.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Why did Stephen Hawking argue for space colonization as a means of saving humanity?\n",
            " Stephen Hawking argued for space colonization as a means of mitigating proposed impacts of overpopulation on Earth, such as resource depletion. He believed that if the resources of space were opened to use and viable life-supporting habitats were built, Earth would no longer define the limitations of growth. This would allow for the majority of the planet's resource requirements to be satisfied by extraterrestrial resources, reducing demand on terrestrial ones.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How does the mass launcher use the principle of the linear induction motor to launch lunar material?\n",
            " The mass launcher uses the principle of the linear induction motor by having liquid helium-cooled superconducting magnets built into the walls of each bucket, which suspend it above the track. The buckets are then accelerated at 30 g over 10 km by a linear electric motor running the length of the track. Once the bucket reaches lunar escape velocity and the velocity is correct, the payload is released and rises relative to the lunar surface, proceeding into space. After releasing the payload, the bucket is decelerated and returned to the loading end of the track.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the advantages of locating the colony in large orbits around L4 and L5?\n",
            " Advantages of locating the colony in large orbits around L4 and L5 include stable gravitational equilibrium points, requiring minimal station-keeping, and allowing simplified design and less fuel consumption for transportation. These locations also offer greater security against potential collisions with space debris.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are alternative biochemistries and how do they relate to the search for extraterrestrial life?\n",
            " Alternative biochemistries refer to the prospect of life forms based on biological processes different from the ones found on Earth. These could involve different fundamental elements or molecular structures. The text does not delve into specific alternative biochemistries, but it does imply that life as we know it is based on carbon, hydrogen, oxygen, and nitrogen. The search for extraterrestrial life often assumes similar biochemistries due to the abundance of these elements in the universe. However, the existence of alternative biochemistries could broaden the possibilities for life in places with different elemental abundances or conditions inhospitable to carbon-based life.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the significance of water availability in determining habitability?\n",
            " Water availability is crucial for habitability as it is necessary for biological processes to take place and is the solvent in which the first reactions occurred that led to life's emergence. In addition, the vast majority of water necessary for life on Earth is believed to have come from the outer Solar System, deposited by comets impacting with the Earth in its early years, providing a kick-start to the origin of life.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the significance of the list of extrasolar planet candidates released by the Kepler Space Observatory Mission team?\n",
            " The list of extrasolar planet candidates released by the Kepler Space Observatory Mission team is significant because it represents a major step towards finding planets in the habitable zones of their stars and potentially finding Earth-sized planets. This list has contributed to the discovery of several potentially habitable exoplanets.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are some arguments against using space colonization as a solution to human overpopulation?\n",
            " Some arguments against using space colonization as a solution to human overpopulation include:\n",
            "\n",
            "1. Physical impracticality: Shipping vast numbers of people into space to \"solve\" overpopulation on Earth may not be physically practical.\n",
            "2. Focus on exploitation: Changing only the location but not the logic of exploitation will not create a more sustainable future.\n",
            "3. Cost and risk: The high cost of investment, long period required for expected return on those investments, and the high-risk nature of such investments are significant impediments to commercial exploitation of space resources.\n",
            "4. Alternatives available: Slowing population growth rates since the 1980s have alleviated the risk of overpopulation, making space colonization less pressing as a solution.\n",
            "5. Economic unfeasibility: The costs of commercial activity in space are too high to be profitable against Earth-based industries, making it unlikely to see significant exploitation of space resources in the foreseeable future.\n",
            "6. Power imbalance: Space colonization and commodification of the cosmos are likely to enhance the interests of the already powerful, including major economic and military institutions, potentially leading to greater inequality.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are some arguments for and against space settlement?\n",
            " Some arguments for space settlement include the survival of human civilization and life on Earth in the event of a planetary-scale disaster, and the availability of additional resources in space that could enable expansion of human society. Common objections include concerns about the commodification of space, the high costs and technological challenges involved, ethical considerations regarding the ownership and use of extraterrestrial resources, and potential negative impacts on the environment and indigenous cultures.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the role of electrical supply and distribution in a space colony?\n",
            " The text does not provide explicit information on the role of electrical supply and distribution in a space colony. However, it can be inferred that electrical supply and distribution would be a critical component of a space colony's infrastructure, necessary for powering a wide range of systems and processes, including life support systems, manufacturing, transportation, and communication. The text also mentions the importance of commercial productivity as a goal for the design of space colonization, which might imply the need for a reliable and efficient electrical supply and distribution system to support economic activities such as the manufacture of solar power satellites.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the proposed trajectory for mankind's expansion into space colonization?\n",
            " The proposed trajectory for mankind's expansion into space colonization includes utilizing space resources to meet the majority of Earth's resource requirements, thereby reducing demand on terrestrial resources. Proponents argue that space colonization could alleviate overpopulation and resource depletion on Earth. However, critics question the practicality of deploying vast numbers of people into space to solve overpopulation on Earth.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the purpose of a heavy lift launch vehicle in space colonization?\n",
            " The text does not mention the purpose of a heavy lift launch vehicle in space colonization. However, generally, a heavy lift launch vehicle is used in space colonization for transporting large payloads, such as space station modules, large satellites, or interplanetary spacecraft, into orbit.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the advantages and disadvantages of the Bernal sphere as a habitat configuration?\n",
            " The Bernal sphere is a spherical geodesic dome that is particularly efficient in its geometrical and shielding requirements. It needs 300,000 tons less shielding than the banded torus and millions of tons less than any other configuration. However, the Bernal sphere requires from 3 to 4 times as much atmospheric mass as other forms and from 2 to 4 times as much structural mass. The spherical design has been named after J. D. Bernal and features agriculture placed in thin toruses outside the shielded sphere. It has been identified as a potential habitat design for space colonization.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What factors affect the economic viability of space colonization for the production of SSPS's?\n",
            " Several factors affect the economic viability of space colonization for the production of SSPS's (Solar Power Satellites). These include:\n",
            "\n",
            "1. Second and later colonies: The construction of additional colonies affects total costs as production activities expand, requiring more lunar materials.\n",
            "\n",
            "2. Repayment to Earth: Space colonies have the ability to repay Earth for their initial and operating costs by supplying energy from space, mostly after the first colony is finished and operating.\n",
            "\n",
            "3. Time horizon: Extending the time horizon of the program introduces cost uncertainties and suggests changes in the system that would be likely to increase its economic productivity.\n",
            "\n",
            "4. Optimization based on SSPS production: Building several construction shacks first and then building SSPS's and colonies simultaneously can optimize the process. Colonies have less total cost than construction shacks, but shacks are more quickly built and cost less.\n",
            "\n",
            "5. Increased lunar materials: As production activities expand, more lunar materials are needed until the capacity of the initial mass launching system is exceeded. To move more material from the Moon will require more power there. An SSPS in lunar synchronous orbit should be considered instead of another nuclear station.\n",
            "\n",
            "6. Market size and penetration: The market size for SSPS's is assumed to increase 5 percent per year, and it is assumed that 10 years are needed for full penetration of the electricity market by SSPS's.\n",
            "\n",
            "7. Costs and benefits: The economic advantage of space operations would be improved if benefits to foreign nationals from lower electricity costs, and to colonists, are included in the analysis.\n",
            "\n",
            "8. International organization: An international organization to fund the colonization program would bring even greater benefits to terrestrial Americans as it would spread out the costs.\n",
            "\n",
            "These factors should be carefully considered and managed to ensure the economic viability of space colonization for the production of SSPS's.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What factors were considered in determining the size and distribution of the population in the space colony design?\n",
            " Factors considered in determining the size and distribution of the population in the space colony design include ensuring at least 40 m^2 of projected area per inhabitant to minimize the sense of crowding and providing needed services. This area is projected onto the largest plane perpendicular to the direction of pseudogravity, and actual usable area can be made larger than projected area by constructing levels within a habitat. The design aims to organize this space to minimize crowding while still providing required services, similar to developing a land-use plan for Earth cities.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are some proposed models of transplanetary or extraterrestrial governance in the context of space colonization?\n",
            " Proposed models of transplanetary or extraterrestrial governance in the context of space colonization are based on international treaties such as the Outer Space Treaty and Moon Treaty, as well as national laws. These treaties establish that space activity should be carried out for the benefit and in the interests of all countries and that outer space is not subject to national appropriation by claim of sovereignty. Space law has become a larger legal field that also includes diverse national laws.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What role did NASA play in determining the habitability of KOI-1686.01?\n",
            " NASA proved KOI-1686.01 to be a false positive in 2015, thus determining it is not a potentially habitable exoplanet.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the effects of isolation in closed environments on the mental and emotional health of colonists in space colonization?\n",
            " Isolation in closed environments aboard space colonies can lead to depression, sleep disorders, and diminished personal interactions. These issues are likely due to confined spaces and the monotony and boredom of long space flight. Additionally, circadian rhythm may be affected by the disrupted timing of sunset and sunrise, leading to exhaustion, insomnia, and other sleep problems, which can further impact mental health and productivity.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m6\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m7\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m8\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m9\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m10\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m11\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m12\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m13\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m14\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m15\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m16\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m17\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m18\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the characteristics of TOI-700_d?\n",
            " TOI-700_d has a mass of approximately 1.72 Earth masses, a radius of 1.14 Earth radii, a surface temperature of 246 Kelvin, and orbits its star, TOI-700 (an M2V type star), every 37.4 days at an orbital distance of 101 stellar radii.\n",
            "___________________________\n",
            "{\"concise\": true}\n",
            "{ \"relevant\": true }\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How is a solar furnace used in the production of aluminum from lunar soil?\n",
            " A solar furnace is used to generate high temperatures needed for the melt-quench-leach production of alumina, followed by high-temperature electro-winning of aluminum from aluminum chloride. The solar furnace provides the necessary heat for these processes, enabling the refining of aluminum from lunar anorthosite.\n",
            "___________________________\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": false}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"conscise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": false}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": false}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{ \"accurate\": true }\n",
            "{\"concise\": false}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m19\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m20\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"concise\": false}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 1590.56it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f9-896d-7190-a51c-7fa7a8fd719e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f9-8c28-76a0-b2df-423b377f963a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f9-8e6b-7f40-83d1-bad1f16b287f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f9-9cf5-7b31-b3c2-4d054e73137f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f9-a01c-70c2-8caf-f23b910c1240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f9-a332-7061-b0f6-d3e4c7ad2590\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f9-a646-7140-8a76-26538d4d5344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:09<00:00,  9.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f9-a99b-72f0-829a-aa0350b2ba36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 6553.60it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f9-b29e-72b0-9d92-917775771d9c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f9-b627-7db2-8284-68890eaa6ec3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f9-bc78-7170-9731-be6a22f723bc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f9-c602-7b72-8342-139b4288f844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f9-c8e3-7ef1-adf0-5e8e68d755b8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:07<00:00,  7.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f9-cc1a-7730-9611-3fbe087dd560\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 609.37it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f9-d496-7100-90d4-0a2611722d9c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f9-d733-77e2-940d-e2bac788c2d0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f9-d94b-7f01-9caa-27dfeab937b6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f9-e9ee-7201-8193-2482b7000505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f9-ef3d-76d2-9324-a6cc5202b7e3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f9-f26e-7c90-b228-0a4ee125c739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f9-f597-79a0-bd6f-f85c7e62376d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:10<00:00, 10.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f9-f894-7ae0-82f0-4b9a99b1f646\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 781.06it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-0145-7c30-8085-8bf4bd977bcd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-03a7-7073-9e6f-3ac5428eed20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-066b-7be1-9c13-d659dff28995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-1356-7a12-a377-4c3a8a738dc7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:06<00:00,  6.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-16b2-7e52-91fe-3594d2dc2a58\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 6820.01it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-1f78-7b73-b1d4-6ea21fea9a4f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-21f5-79f0-9079-cc820c538328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-24d7-7603-a699-9ddd3c153a9e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-3c62-7e83-94bc-6a4323d57659\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-3fe0-75d3-ab53-66acef75897e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-430b-7662-9cbd-265bc902b832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-45f0-7e93-8955-b0be75e4f0c7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:11<00:00, 11.84s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-4ab1-7770-8796-0cb35ccdcf08\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7256.58it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-59b4-7721-96af-d6287f20a4c7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-5c61-7662-bac6-1f87bf045c55\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-5ee3-7ff0-abf1-0283191e2628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-6c6d-7232-9682-e3f1521db00f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-6f6e-7923-a3d0-f08bd140d0d8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-7383-7023-9e37-aa10b631c8c5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:08<00:00,  8.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-76c5-79b2-8fe1-68b5dcb43503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7543.71it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-7f01-77f1-8cd8-8bfeeacafbb4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-8152-7dd0-be7c-882e6c306164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-8452-79a3-adaf-e1518668f4d0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-9449-7ad1-ab95-4ec7c0b291e5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-97e2-77d3-8363-9f88892eaf20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-9b60-7040-a4c7-f8561c523689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:09<00:00,  9.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-9eb8-7ab1-9fac-3db5290fc2e6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 5966.29it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-a7e7-7270-b302-687d13fc7eca\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-aa7d-7861-83d7-4a7715f39510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-ac7f-7490-8eee-63e51c7b59be\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-cacb-78c0-bdc4-505929b030d4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-cdef-7b60-841a-7b0b3abb9f60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-d17f-7ac2-86f8-b5246a38e24c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-d4ab-7180-a3f1-df791c9a5115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-d859-7c20-bc68-1dba30a30a87\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:13<00:00, 13.93s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-db6d-74c0-9501-41df4deb4030\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 1492.10it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-e3b0-79c3-b6c4-787267580f9e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-e69b-71f3-9b19-d820d2344977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-e8cd-7592-8aa9-e7cac085b102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fa-f9e7-7012-8dce-2638363e6a44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-0054-72b3-8f6f-02a777fb5b2a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-03a8-7a92-91ca-3085a900065c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-076e-7040-bbd5-94aca122b154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-0b70-7f20-9cd2-f17fa43da3bc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:11<00:00, 11.96s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-0ef6-7c13-bb79-aaf5a0593691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 1751.28it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-17d5-7f91-ab13-42d641f3d9b4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-1c7c-74d0-a2fd-28e4b190642b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-1fe2-7be1-a646-9d337b8575b1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-3476-70e2-ab12-7449f1d1c494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-37ce-7c71-a5ce-1de024ceac8d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-3c96-7510-8400-b8efbce632a7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-3fb1-7941-957f-ee682f021737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:12<00:00, 12.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-4325-71e2-bef0-e2035059fe13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7371.36it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-4c09-7812-9d57-f92ee7243cf7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-4fc9-7e91-be46-d0a10047f846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-521d-7a61-99f3-faf5e8b82eed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-61c5-74f2-b2e1-804a07e6639d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-67c4-7451-bd5e-beac9b13b594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-6b76-76b1-9a67-f07ec214d15c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:11<00:00, 11.79s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-76d0-7590-b581-4fc8baade581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 1240.92it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-7fa0-7e91-8cc0-2cebf7ac38c2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-822c-7910-a235-5157c059acf0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-847a-7341-b2b3-fd1b7db6bf21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-9195-7291-9db6-f18b00a55c74\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-94d0-7413-98fe-fcf3f097afa9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-9847-7fd1-b23f-84aca9b275d3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:08<00:00,  8.56s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-9b53-7eb3-a0ba-d19ae5ad6ce6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 6553.60it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-a64b-75a1-bca4-5bc0ac3e4a24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-a8aa-7da2-8896-d22a16e75738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-abc2-7a83-8070-bf8faa2688ec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-c674-7a02-a544-a85d17c7618f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-cd01-7050-9751-366cf2a8e9b8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-d2f8-7d92-a668-4d08910877e4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fb-d65e-7e92-b552-99f8dd2e004d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-0429-7fd1-b0db-0fafe3fc018d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-07df-7773-9215-7049d5b13823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:26<00:00, 26.85s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-0b6e-70a2-be2c-c0136258c880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 6316.72it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-146c-7682-9064-35670f440fe2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-173c-7610-b051-0a94666cd56d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-1987-7580-b415-44df406fa77c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-5c3b-7a51-aa48-4f1594b64ef2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-5fd8-73e3-b9a9-3265570ca580\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-6404-7c51-8cff-5bcdeebcd8c2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-67aa-7aa1-843c-8e5acb814b0f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-6bb0-77a2-84d7-e4109fde9a19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-73db-7cf2-a3e7-06691fa25634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-79ac-79c2-8fa9-61e070677970\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:27<00:00, 27.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-7d33-7943-974d-2a55ca6901aa\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 741.83it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-85f0-7783-9de9-13085be3af6a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-8856-7c50-a35b-c373aa5681ee\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-8aa3-76c3-b86e-ef005bcda4b9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-9ab5-7801-8836-a66f766cc81e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-9dfd-7a91-a3e7-7c1e535dffae\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:08<00:00,  8.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-a258-7d83-97b0-78b2f5446202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 755.32it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-ab6a-7bf1-b95b-1d07b8cc9913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-af1a-7ad1-ad42-6b9b3a2665fa\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-b1ee-76c3-95cf-8f254ae72f0f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-c0a8-7572-b0c2-9edfc429ee91\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-c606-7570-8c4b-8e18673c1300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-c8f7-7132-b0ba-735e7fccafdd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:09<00:00,  9.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-ccfd-72b1-9c1b-a0dfcc155e7d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 1544.86it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-d599-76b0-82c3-a4ce53dabcd3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-d7d0-74f3-a39b-3d5d132a5535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-dc00-7ec2-be42-d4bf4e58da1b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-e2d9-7000-9393-1582b8ceb637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:05<00:00,  5.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-e60b-7aa1-98b8-1b1372ba3c11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 1480.52it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-eed1-7651-bc4a-3a7bac672f7a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-f14f-7b02-89e4-68e28ffa894c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-f338-7c60-a753-0b3bedd33785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fc-ff30-7fe0-9cc5-54042c9f914a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fd-0263-7371-870e-beb1a7e54a46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fd-0711-7333-a75e-051a030b510b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:07<00:00,  7.85s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fd-0a70-7a80-8adb-82a45ce8f034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 749.52it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fd-12c3-7500-81b6-c1112ede63d3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fd-159c-75e2-837c-d47c74be8e02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fd-179b-7cd2-9266-f20a72ce0e99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fd-23db-7121-bed5-100f3d0a9566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fd-26f1-7870-a190-9375f12b1c9d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fd-2c94-7a41-a1bf-a915efca3a36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fd-2fcb-71f3-8705-8fc9694767a7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:09<00:00,  9.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fd-3416-7743-a210-aa465be0103c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 5769.33it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fd-3cea-7590-8cce-16288edf2720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fd-420a-7672-ba3e-4ec83f18e1d6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fd-4482-7200-9e41-e9a1f0b2be07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fd-5069-7523-8747-f4606575d1dd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fd-5516-7322-8e34-c8d7f5ab2705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fd-57f8-7130-ada5-b72008206778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fd-5b18-7a03-82d2-306f5b790f95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fd-5e03-7ce1-a6db-511a1af54910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fd-60e5-7ab3-9492-00f3b9f9bcf7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fd-63b6-7a43-b986-4d0dcb475152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:11<00:00, 11.96s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fd-6834-7030-984e-b1e09f8ec430\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the psychological challenges faced by astronauts during prolonged space missions?\n",
            " The text does not provide specific information on psychological challenges faced by astronauts during prolonged space missions. However, it does mention the importance of providing for psychological and esthetic needs of colonists in space. It suggests that substantial savings in structural mass, cost, and construction time could be obtained by deviating from Earth-like conditions, but physiological effects of such deviations are unknown, so living conditions in space are designed to be similar to those on Earth.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How does volcanic activity affect the colonization potential of the Saturnian moons?\n",
            " The provided context does not discuss the colonization potential of the Saturnian moons in relation to volcanic activity, as it focuses primarily on Jovian moons. However, among the Saturnian moons, Enceladus has been observed to have cryovolcanic activity, which might potentially affect its colonization potential but this is not explicitly mentioned or explored in the provided context.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What factors limit the habitability of exoplanets around red dwarf stars?\n",
            " Tidal locking, requiring planets to be extremely close to the star for Earth-like temperatures, the potential for extreme flares eroding the planet's atmosphere, and the possibility of thick atmospheres blocking sunlight needed for photosynthesis are factors that limit the habitability of exoplanets around red dwarf stars.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the significance of solar power satellites in the design for space colonization?\n",
            " Solar power satellites (SPS) are a significant export in the initial space settlement designs. They use wireless power transmission to send power to locations on Earth or other space colonies. Once primarily built from lunar or asteroid-derived materials, SPS electricity could potentially be cheaper than fossil fuel or nuclear energy. SPS also has the advantage of being extremely benign with zero emissions and less ground area required per watt than conventional solar panels. In space, the value of SPS power is typically far higher than on Earth, making them a priority for electricity supply to other locations in space.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the chosen method for refining aluminum from lunar anorthosite?\n",
            " The chosen method for refining aluminum from lunar anorthosite is melt-quench-leach production of alumina followed by high temperature electro-winning of aluminum from aluminum chloride.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How does the expense of providing human workers encourage reliance on automation and push for extreme reliability and maintainability in space commercial ventures?\n",
            " The passage does not provide direct information on the expense of human workers in space commercial ventures. However, it mentions that progress in automation is expected, which might be encouraged by the high cost of human labor in space. This automation would likely require extreme reliability and maintainability to ensure minimal maintenance and repairs in space.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the suggested advantageous locations for colonization according to Robert Zubrin?\n",
            " Robert Zubrin has suggested Saturn, Uranus, and Neptune as advantageous locations for colonization because their atmospheres are good sources of fusion fuels, such as deuterium and helium-3. He specifically noted that Saturn would be the most important and valuable as it is the closest and has an excellent source of these fuels.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the chief assumptions about habitable planets in terms of their characteristics?\n",
            " Habitable planets are assumed to be rocky, wet terrestrial-type planets or moons with the potential for Earth-like chemistry. They are expected to have bulk composition, orbital properties, atmosphere, and potential chemical interactions favorable for life. Stellar characteristics of importance include mass, luminosity, stable variability, and high metallicity.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How has space colonization been discussed as a continuation of imperialism and colonialism?\n",
            " Space colonization has been discussed as a continuation of imperialism and colonialism, as it has been criticized for being a postcolonial practice that primarily benefits wealthy elites and private corporations. Critics argue that the present politico-legal regimes and their philosophic grounding favor imperialist development of space and that key decision-makers in space colonization are often affiliated with private corporations. It has also been argued that there is a need for inclusive and democratic participation in any space exploration, infrastructure, or habitation. The narrative of the \"New Frontier\" has been criticized as an unreflected continuation of settler colonialism and manifest destiny, and space has been identified as a new sacrifice zone of colonialism. The advocacy for territorial colonization of Mars opposed to habitation in the atmospheric space of Venus has been called surfacism, a concept similar to surface chauvinism.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are some criticisms of space colonization?\n",
            " Some criticisms of space colonization are that the costs are too high to be profitable against Earth-based industries, making significant exploitation of space resources unlikely. Others argue that a slowdown in population growth rates since the 1980s has alleviated the risk of overpopulation, making space colonization less necessary as a solution to that problem. Additionally, concerns have been raised that colonization and commodification of the cosmos could enhance the interests of already powerful institutions like major economic, aerospace, and military entities.\n",
            "___________________________\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m21\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m22\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m23\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m24\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m25\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m26\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m27\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m28\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m29\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m30\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m31\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m32\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m33\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m34\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m35\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m36\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m37\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"concise\": false}\n",
            "{\"relevant\": false}\n",
            "{ \"accurate\": false }\n",
            "{\"concise\": true}\n",
            "{\"relevant\": false}\n",
            "{\"accurate\": false}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n",
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m38\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">38</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m39\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">39</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m40\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"concise\": true}\n",
            "{\"relevant\": true}\n",
            "{\"accurate\": true}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7244.05it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-23ed-7ce0-9dd8-9dbc36aa7c39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-2686-7dd0-b39f-5111f9b247f0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-288e-75c3-95cf-c1bc58eb4417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-3f10-7d03-af3a-68a5b8ead779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-420f-7580-8bd9-51486cc3f915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-4548-7fc2-8b38-42b0d1794e48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-4888-7300-ad9c-36ebee591850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-544a-74e3-a7d7-33112049c1e2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:15<00:00, 15.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-5a2c-74a2-addc-c3e32376b119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 6307.22it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-64b3-77c0-909c-34bb8c40fd7b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-6f3f-7673-b340-5293c9731f81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-72f8-7e70-871e-78674e09793d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-8477-77e3-8132-55d3116214ab\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-8814-7930-b10c-3d8e6377d8d3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-8c2d-79e0-a9de-82cb4c48caee\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:13<00:00, 13.14s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-9156-75b0-b59b-9bdb381fd100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7869.24it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-9f37-72c3-88d6-2b51f35925a1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-a3be-7300-9850-b72c8649939c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-a5f9-75e0-abbc-f4121c59ac01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-ae26-7c53-a6c8-5a7ada9000ec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-b256-7f70-9828-a13992380069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-bc7b-7fc1-a253-af6200e3937c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:09<00:00,  9.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-bff0-7403-99fd-5166c672ec54\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 8004.40it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-c87a-7250-9483-38239433e095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-cb4f-7b63-9639-49105de3ee18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-cdaa-7c62-9f7a-ace5f4952024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-e338-7601-89dd-e87e2b97fb64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-e6f1-77a3-8e8e-bedcdfabe100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-ea20-7161-8716-dbcbf6a5786a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-ed7f-71a1-9252-c24872e25708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:11<00:00, 11.73s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-f0af-7402-b761-5ebaf482c8e7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 1588.15it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-fbaf-7a01-a472-e9606a7d6d72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8fe-fdec-79c2-b156-fb9e96c09515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-0182-7d12-b808-b9a5cf916067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-090e-7cc3-a4f0-1d4ca4bad091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-0bf3-7740-af94-1df7cd65c5fd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-0e92-7ef0-b9dc-7811a65aec8c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-1124-7c52-8b7a-2c63f73e9291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:06<00:00,  6.98s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-147f-77f2-a2e9-806a24ec5808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7332.70it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-1c35-7273-8ece-3dbd3b815aa7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-1e6d-7f10-964d-54595e48f688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-20e1-7181-9cf8-ce4ff32048c1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-2d81-7373-9e9e-2d1bd5d19291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-310f-79b3-b6b8-ef28c921cf54\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:07<00:00,  7.27s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-3483-7813-b5e4-c71b05e4b889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 694.77it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-3dba-7723-b586-e8f27662ecc2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-4010-7353-b178-78ffeeff58bb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-425a-7e61-b454-c038d9bf7315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-4e13-7463-8cb0-5c904c067d7f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-5171-7bc2-8e32-3ffdadc9d260\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-5519-7811-96b5-e81f11546a9f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:07<00:00,  7.72s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-5894-7663-945c-b81a6f019768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 1536.94it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-614e-7432-af00-336b73ad5673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-63aa-7c50-80c7-d94076bfb3dc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-6610-7403-acf9-b7329e8daed2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-71db-7350-aa0f-c3f0ea4663db\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-7540-7303-b1fe-c4c588ef9a87\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:06<00:00,  6.79s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-7857-7a60-8b06-181c1367b465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 7371.36it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-822c-7363-bc9d-a40a13480e48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-8474-71d1-874a-e0fcca919a18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-8673-7290-a01c-6eab6f3edb41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-9e04-7332-9b5a-96aa6ed113d0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-a34d-7eb1-9968-19e19e84c6b7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-a681-73e2-9bc5-aa9ceed17d11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-a9a2-7c21-aac9-47d3695e8900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-ace5-7dc0-bedc-5016527ac9c3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-b0b4-70a1-85bc-1abc9f757115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-b48c-7300-801d-868b29bec371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:14<00:00, 14.80s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-b7c0-7c70-9e36-cc6a87a1993d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 1662.43it/s]\n",
            "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-c130-7a03-970d-ee0175e88a61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-c3e4-7051-8663-6b6ba596cd9f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-c623-78c0-87f4-fa87d48eb9df\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-e075-7dc2-9bb6-7e71e88c239e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-e3a3-7df0-ab0c-48bf5f9203b2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Scoring responses: 100%|██████████| 1/1 [00:10<00:00, 10.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8ff-e6b0-7021-95ee-85f608ef0647\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m41\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m42\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m43\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m44\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">44</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m45\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">45</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m46\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m47\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m48\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m49\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m50\u001b[0m of \u001b[1;36m50\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation summary\n",
              "\u001b[1m{\u001b[0m\n",
              "    \u001b[32m'llm_judge_scorer'\u001b[0m: \u001b[1m{\u001b[0m\n",
              "        \u001b[32m'relevant'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m46\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.92\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'conscise'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m1.0\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'concise'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m41\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.8723404255319149\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'accurate'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m44\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.88\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'concordant'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.0\u001b[0m\u001b[1m}\u001b[0m\n",
              "    \u001b[1m}\u001b[0m,\n",
              "    \u001b[32m'tonic_validate_score'\u001b[0m: \u001b[1m{\u001b[0m\n",
              "        \u001b[32m'answer_consistency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.8608095238095238\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'duplication_metric'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.12\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[32m'answer_similarity'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m3.76\u001b[0m\u001b[1m}\u001b[0m\n",
              "    \u001b[1m}\u001b[0m,\n",
              "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m42.322716007232664\u001b[0m\u001b[1m}\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
              "<span style=\"font-weight: bold\">{</span>\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'llm_judge_scorer'</span>: <span style=\"font-weight: bold\">{</span>\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'relevant'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.92</span><span style=\"font-weight: bold\">}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'conscise'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'concise'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8723404255319149</span><span style=\"font-weight: bold\">}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'accurate'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">44</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.88</span><span style=\"font-weight: bold\">}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'concordant'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span><span style=\"font-weight: bold\">}</span>\n",
              "    <span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'tonic_validate_score'</span>: <span style=\"font-weight: bold\">{</span>\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'answer_consistency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8608095238095238</span><span style=\"font-weight: bold\">}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'duplication_metric'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.12</span><span style=\"font-weight: bold\">}</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'answer_similarity'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.76</span><span style=\"font-weight: bold\">}</span>\n",
              "    <span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42.322716007232664</span><span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍩 https://wandb.ai/lavanyashukla/spacerag_novtest2/r/call/0192f8f3-aacb-7140-8741-3de9318fb03f\n"
          ]
        }
      ],
      "source": [
        "models = [\"meta-llama/Meta-Llama-3-70B-Instruct-Turbo\",\n",
        "          \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
        "          \"mistralai/Mixtral-8x22B-Instruct-v0.1\"\n",
        "          ]  # 🛠️LEVER\n",
        "for model in models:\n",
        "    rag_model = SpaceRAGModel(model=model)\n",
        "    model_name = model.split('/')[-1]  # Get only the part after the '/'\n",
        "    evaluation = Evaluation(name=f\"spacerag-{model_name}\", dataset=small_questions, scorers=[\n",
        "    llm_judge_scorer,\n",
        "    # ragas_score,\n",
        "    tonic_validate_score\n",
        "])\n",
        "    print(f\"RAG Model: {model}\")\n",
        "    await evaluation.evaluate(rag_model, __weave={\"display_name\": f\"spacerag-{model_name}\"})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "bLGtl-vM7yLu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "name": "SpaceRAG-initial.ipynb",
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}